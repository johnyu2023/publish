<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>神经网络基础 | AI时代的技术分享</title>
    <meta name="description" content="神经网络基础">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/publish/assets/style.C2VwB-Fy.css" as="style">
    <link rel="preload stylesheet" href="/publish/vp-icons.css" as="style">
    
    <script type="module" src="/publish/assets/app.DJNUep3v.js"></script>
    <link rel="preload" href="/publish/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/publish/assets/chunks/framework.CdkaGE7W.js">
    <link rel="modulepreload" href="/publish/assets/chunks/theme.ojWqhCPx.js">
    <link rel="modulepreload" href="/publish/assets/chunks/katex.ChWnQ-fc.js">
    <link rel="modulepreload" href="/publish/assets/chunks/dagre-6UL2VRFP.DnEn8kjh.js">
    <link rel="modulepreload" href="/publish/assets/chunks/cose-bilkent-S5V4N54A.DsgziNg3.js">
    <link rel="modulepreload" href="/publish/assets/chunks/c4Diagram-YG6GDRKO.uEImUTjx.js">
    <link rel="modulepreload" href="/publish/assets/chunks/flowDiagram-NV44I4VS.DjwMJLuH.js">
    <link rel="modulepreload" href="/publish/assets/chunks/erDiagram-Q2GNP2WA.SKkgDt9p.js">
    <link rel="modulepreload" href="/publish/assets/chunks/gitGraphDiagram-NY62KEGX.fTXnCR_a.js">
    <link rel="modulepreload" href="/publish/assets/chunks/ganttDiagram-LVOFAZNH.BuZsJTpu.js">
    <link rel="modulepreload" href="/publish/assets/chunks/infoDiagram-F6ZHWCRC.D9i_U-T5.js">
    <link rel="modulepreload" href="/publish/assets/chunks/pieDiagram-ADFJNKIX.DZ_Rpslp.js">
    <link rel="modulepreload" href="/publish/assets/chunks/quadrantDiagram-AYHSOK5B.B2zDLyXy.js">
    <link rel="modulepreload" href="/publish/assets/chunks/xychartDiagram-PRI3JC2R.DmSKb7lp.js">
    <link rel="modulepreload" href="/publish/assets/chunks/requirementDiagram-UZGBJVZJ.CfYu06Op.js">
    <link rel="modulepreload" href="/publish/assets/chunks/sequenceDiagram-WL72ISMW.DnOpnkJy.js">
    <link rel="modulepreload" href="/publish/assets/chunks/classDiagram-2ON5EDUG.DpxWYP2d.js">
    <link rel="modulepreload" href="/publish/assets/chunks/classDiagram-v2-WZHVMYZB.DpxWYP2d.js">
    <link rel="modulepreload" href="/publish/assets/chunks/stateDiagram-FKZM4ZOC.CIjAzRq9.js">
    <link rel="modulepreload" href="/publish/assets/chunks/stateDiagram-v2-4FDKWEC3.DBJDav9Q.js">
    <link rel="modulepreload" href="/publish/assets/chunks/journeyDiagram-XKPGCS4Q.ZFvrGgJx.js">
    <link rel="modulepreload" href="/publish/assets/chunks/timeline-definition-IT6M3QCI.vFKBuu-3.js">
    <link rel="modulepreload" href="/publish/assets/chunks/mindmap-definition-VGOIOE7T.DA7H-JSd.js">
    <link rel="modulepreload" href="/publish/assets/chunks/kanban-definition-3W4ZIXB7.B2xfn5M4.js">
    <link rel="modulepreload" href="/publish/assets/chunks/sankeyDiagram-TZEHDZUN.Venej9id.js">
    <link rel="modulepreload" href="/publish/assets/chunks/diagram-S2PKOQOG.YN5XB0Jl.js">
    <link rel="modulepreload" href="/publish/assets/chunks/diagram-QEK2KX5R.CFVQ_6I0.js">
    <link rel="modulepreload" href="/publish/assets/chunks/blockDiagram-VD42YOAC.C1bkPs94.js">
    <link rel="modulepreload" href="/publish/assets/chunks/architectureDiagram-VXUJARFQ.CY1Rxlzh.js">
    <link rel="modulepreload" href="/publish/assets/chunks/diagram-PSM6KHXK.ByKwy9gD.js">
    <link rel="modulepreload" href="/publish/assets/chunks/virtual_mermaid-config.CQTEIV6y.js">
    <link rel="modulepreload" href="/publish/assets/ai_neural-network-basic.md.BbrnK0yi.lean.js">
    <link rel="alternate" type="application/rss+xml" href="/publish/rss.xml" title="RSS Feed for AI时代的技术分享">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
    <style>
      body {
        background-color: #f0f0f0 !important;
      }
      .debug-message {
        position: fixed !important;
        top: 20px !important;
        left: 20px !important;
        background-color: purple !important;
        color: white !important;
        padding: 20px !important;
        font-size: 16px !important;
        z-index: 9999 !important;
      }
      
      /* 非常明显的全局测试样式 */
      .global-test-banner {
        position: fixed !important;
        top: 100px !important;
        left: 0 !important;
        right: 0 !important;
        background-color: yellow !important;
        color: black !important;
        padding: 30px !important;
        font-size: 24px !important;
        font-weight: bold !important;
        text-align: center !important;
        z-index: 9998 !important;
      }
    </style>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/publish/" data-v-1168a8e4><!--[--><!--]--><!----><span data-v-1168a8e4>AI时代开发之旅</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/publish/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>首页</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/publish/list" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>文章</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/publish/about" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>关于</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/johnyu2023" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="/publish/rss.xml" aria-label="rss" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-rss"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/johnyu2023" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="/publish/rss.xml" aria-label="rss" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-rss"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--[--><button style="background-color:gray;color:white;border:none;border-radius:4px;padding:10px 15px;font-size:16px;cursor:pointer;width:100%;text-align:center;margin-bottom:10px;transition:background-color 0.3s;">高级导航</button><!--]--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 collapsible has-active" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>学习笔记</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b3fd67f8><span class="vpi-chevron-right caret-icon" data-v-b3fd67f8></span></div></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/tensorflow" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>TensorFlow 基础</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/neural-network-basic" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>神经网络基础</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/time-series-analysis" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>时间序列分析</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/used-car" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>二手车预测价格大赛</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/ai-algorithms-in-different-fields" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>不同领域的 AI 算法</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/analytical-ai-01" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>分析式AI 01</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/rag01" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>RAG 01</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/vector-database" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>向量数据库</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/embeddings" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Embeddings</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/coze-01" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Coze 使用 01</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/slm" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>小语言模型的春天到了吗</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/ai-images-01" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>AI 生图使用</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/function-calling-vs-mcp" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Function Calling vs MCP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/function-calling" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Function Calling 的原始形态</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/ai-basic-01" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>AI 基础 01</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/transformer-02" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Transformer 揭秘02</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/transformer-01" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Transformer 揭秘01</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/neural-network-02" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>神经网络 揭秘02</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/neural-network-01" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>神经网络 揭秘01</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/publish/ai/machine-learning" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>机器学习，深度学习，强化学习</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>On this page</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _publish_ai_neural-network-basic" data-v-39a288b8><div><div class="blog-post" data-v-e602dff2><div class="blog-post-header" data-v-e602dff2><div class="post-title" data-v-e602dff2><h1 data-v-e602dff2>神经网络基础</h1></div><div class="post-meta" data-v-e602dff2><div class="post-date" data-v-e602dff2><span class="date-icon" data-v-e602dff2>📅</span><time datetime="2025-10-04T00:00:00.000Z" data-v-e602dff2>2025年10月04日</time></div></div><div class="post-description" data-v-e602dff2>神经网络基础</div></div><div class="post-content" data-v-e602dff2><!--[--><h2 id="深度学习和神经网络" tabindex="-1"><code>深度学习</code>和<code>神经网络</code> <a class="header-anchor" href="#深度学习和神经网络" aria-label="Permalink to &quot;`深度学习`和`神经网络`&quot;">​</a></h2><blockquote><p>深度学习强调的是深度，也就是很多层的神经网络。</p></blockquote><p>深度学习和神经网络之间是<strong>包含与被包含</strong>的关系：</p><ul><li><strong>神经网络</strong>（Neural Networks）是一种受生物神经系统启发的计算模型，由多个相互连接的“神经元”组成，用于对输入数据进行非线性变换和特征提取。</li><li><strong>深度学习</strong>（Deep Learning）则是<strong>基于深层神经网络</strong>（即包含多个隐藏层的神经网络）的机器学习方法，是机器学习的一个子领域。</li></ul><p>换句话说，<strong>神经网络是深度学习的基础和核心模型</strong>，而深度学习是神经网络发展到“深度”（多层）结构后形成的一种强大技术范式。深度学习通过堆叠多个隐藏层，能够自动学习数据的层次化特征表示，从而在图像识别、自然语言处理等领域取得突破性成果 。</p><p>简要关系链为：<br><strong>人工智能 ⊃ 机器学习 ⊃ 深度学习 ⊃（基于）神经网络</strong> 。</p><h2 id="tensorflow-和-pytorch" tabindex="-1">TensorFlow 和 PyTorch <a class="header-anchor" href="#tensorflow-和-pytorch" aria-label="Permalink to &quot;TensorFlow 和 PyTorch&quot;">​</a></h2><img src="/publish/assets/tensorflow-vs-pytorch.yK_eyk2-.png" alt="neural-networks"><h2 id="numpy-简介" tabindex="-1">NumPy 简介 <a class="header-anchor" href="#numpy-简介" aria-label="Permalink to &quot;NumPy 简介&quot;">​</a></h2><p>在 AI（人工智能）领域，<strong>NumPy</strong> 是一个非常基础且重要的 Python 库，全称为 <strong>Numerical Python</strong>。它主要用于高效处理<strong>多维数组</strong>（尤其是数值型数据），并提供了大量用于<strong>数学、科学和工程计算</strong>的函数。</p><h3 id="numpy-的核心特点" tabindex="-1">NumPy 的核心特点 <a class="header-anchor" href="#numpy-的核心特点" aria-label="Permalink to &quot;NumPy 的核心特点&quot;">​</a></h3><ol><li><p><strong>N 维数组对象（ndarray）</strong><br> NumPy 的核心是 <code>ndarray</code>（N-dimensional array），它是一种高效的多维数组结构，比 Python 原生的列表（list）在存储和计算上更节省内存、速度更快，尤其适合处理大规模数值数据。</p></li><li><p><strong>向量化运算</strong><br> NumPy 支持对整个数组进行数学运算（如加、减、乘、除、三角函数、指数等），而无需显式写 for 循环，这种“向量化”操作极大提升了代码效率和可读性。</p></li><li><p><strong>广播机制（Broadcasting）</strong><br> 允许不同形状的数组之间进行算术运算，自动扩展较小的数组以匹配较大数组的形状。</p></li><li><p><strong>与 C/C++ 和 Fortran 兼容</strong><br> NumPy 底层用 C 语言实现，运行速度快，并可与 C/C++ 或 Fortran 代码集成。</p></li><li><p><strong>生态系统基础</strong><br> NumPy 是许多 AI/ML 库的基础依赖，例如：</p><ul><li><strong>SciPy</strong>（科学计算）</li><li><strong>Pandas</strong>（数据分析）</li><li><strong>Matplotlib</strong>（数据可视化）</li><li><strong>Scikit-learn</strong>（机器学习）</li><li><strong>TensorFlow / PyTorch</strong>（深度学习框架也大量使用或兼容 NumPy 数组）</li></ul></li></ol><hr><h3 id="简单示例" tabindex="-1">简单示例 <a class="header-anchor" href="#简单示例" aria-label="Permalink to &quot;简单示例&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建一个 2x3 的数组</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">              [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对整个数组加 10（向量化操作）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(b)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出：</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [[11 12 13]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#  [14 15 16]]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 计算所有元素的平均值</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mean_val </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.mean(a)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(mean_val)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出：3.5</span></span></code></pre></div><hr><h3 id="为什么-ai-领域离不开-numpy" tabindex="-1">为什么 AI 领域离不开 NumPy？ <a class="header-anchor" href="#为什么-ai-领域离不开-numpy" aria-label="Permalink to &quot;为什么 AI 领域离不开 NumPy？&quot;">​</a></h3><ul><li>AI 模型的输入数据（如图像、文本向量、传感器数据）通常表示为<strong>高维数组</strong>（例如图像为 3D：高度×宽度×通道）。</li><li>模型训练中的矩阵运算（如线性代数、梯度计算）依赖高效的数组操作。</li><li>NumPy 提供了统一的数据结构和接口，使得不同 AI 工具之间可以无缝协作。</li></ul><p>因此，<strong>NumPy 被视为 Python 科学计算和 AI 开发的基石之一</strong>。</p><h2 id="pytorch-是-gpu-上运行的-numpy" tabindex="-1">PyTorch 是 GPU 上运行的 NumPy <a class="header-anchor" href="#pytorch-是-gpu-上运行的-numpy" aria-label="Permalink to &quot;PyTorch 是 GPU 上运行的 NumPy&quot;">​</a></h2><h3 id="_1-pytorch-与-numpy-在-api-设计上高度相似" tabindex="-1">1. <strong>PyTorch 与 NumPy 在 API 设计上高度相似</strong> <a class="header-anchor" href="#_1-pytorch-与-numpy-在-api-设计上高度相似" aria-label="Permalink to &quot;1. **PyTorch 与 NumPy 在 API 设计上高度相似**&quot;">​</a></h3><ul><li>PyTorch 的张量（Tensor）操作在语法和功能上与 NumPy 的 ndarray 非常相似。</li><li>例如：</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># NumPy</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">c </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> b</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># PyTorch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">c </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> b</span></span></code></pre></div><p>两者在基本操作（加减乘除、索引、reshape、广播等）上几乎一致，学习成本低。</p><hr><h3 id="_2-pytorch-支持-gpu-加速-numpy-默认只支持-cpu" tabindex="-1">2. <strong>PyTorch 支持 GPU 加速，NumPy 默认只支持 CPU</strong> <a class="header-anchor" href="#_2-pytorch-支持-gpu-加速-numpy-默认只支持-cpu" aria-label="Permalink to &quot;2. **PyTorch 支持 GPU 加速，NumPy 默认只支持 CPU**&quot;">​</a></h3><ul><li>NumPy 的计算只能在 CPU 上进行。</li><li>PyTorch 的 Tensor 可以轻松地在 CPU 和 GPU 之间切换，只需指定设备：</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">device </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.device(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cuda&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.cuda.is_available() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;cpu&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]).to(device)</span></span></code></pre></div><p>一旦 Tensor 被放到 GPU 上，后续的运算就会自动在 GPU 上执行，从而获得显著的加速（尤其在深度学习中处理大规模数据时）。</p><hr><h3 id="_3-pytorch-不仅是-gpu-版-numpy-还包含自动微分等深度学习特性" tabindex="-1">3. <strong>PyTorch 不仅是“GPU 版 NumPy”，还包含自动微分等深度学习特性</strong> <a class="header-anchor" href="#_3-pytorch-不仅是-gpu-版-numpy-还包含自动微分等深度学习特性" aria-label="Permalink to &quot;3. **PyTorch 不仅是“GPU 版 NumPy”，还包含自动微分等深度学习特性**&quot;">​</a></h3><p>虽然这句话强调了“GPU 上的 NumPy”，但 PyTorch 实际上远不止于此：</p><ul><li><strong>自动微分（Autograd）</strong>：支持通过 <code>.backward()</code> 自动计算梯度，这是训练神经网络的核心。</li><li><strong>神经网络模块（torch.nn）</strong>：提供构建深度学习模型的高级接口。</li><li><strong>动态计算图</strong>：PyTorch 使用动态图（define-by-run），使得调试和控制流更灵活。</li></ul><p>所以更准确地说：</p><blockquote><p><strong>PyTorch 是一个以 GPU 加速张量计算为基础，并支持自动微分和深度学习的框架，其张量操作 API 与 NumPy 高度兼容。</strong></p></blockquote><hr><h3 id="_4-互操作性-pytorch-与-numpy-可以无缝转换" tabindex="-1">4. <strong>互操作性：PyTorch 与 NumPy 可以无缝转换</strong> <a class="header-anchor" href="#_4-互操作性-pytorch-与-numpy-可以无缝转换" aria-label="Permalink to &quot;4. **互操作性：PyTorch 与 NumPy 可以无缝转换**&quot;">​</a></h3><ul><li>你可以轻松地在 NumPy 数组和 PyTorch Tensor 之间转换：</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># NumPy → PyTorch</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">np_array </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch_tensor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.from_numpy(np_array)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># PyTorch → NumPy（注意：必须在 CPU 上）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch_tensor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">np_array </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch_tensor.numpy()</span></span></code></pre></div><p>这进一步说明两者在设计理念上的紧密联系。</p><h2 id="tpu-是什么" tabindex="-1">TPU 是什么 <a class="header-anchor" href="#tpu-是什么" aria-label="Permalink to &quot;TPU 是什么&quot;">​</a></h2><blockquote><p><strong>TPU -- Tensor Processing Unit</strong>（张量处理单元）的缩写，是 Google 为加速神经网络计算而定制的 AI 芯片，专精于张量运算，在大规模训练和推理任务中具有高性能和高能效的优势，但生态相对封闭，主要通过 Google Cloud 使用。**</p></blockquote><h3 id="_1-tpu-的背景" tabindex="-1">1. TPU 的背景 <a class="header-anchor" href="#_1-tpu-的背景" aria-label="Permalink to &quot;1. TPU 的背景&quot;">​</a></h3><ul><li>TPU 最初由 Google 在 2015 年秘密部署，2016 年正式对外公布。</li><li>它是为了高效运行 <strong>TensorFlow</strong>（Google 开发的深度学习框架）中的大规模神经网络计算而设计的。</li><li>“张量”（Tensor）是深度学习中数据的基本表示形式（如多维数组），TPU 就是专门用来高效处理这类张量运算的硬件。</li></ul><hr><h3 id="_2-tpu-与-gpu-的区别" tabindex="-1">2. TPU 与 GPU 的区别 <a class="header-anchor" href="#_2-tpu-与-gpu-的区别" aria-label="Permalink to &quot;2. TPU 与 GPU 的区别&quot;">​</a></h3><table tabindex="0"><thead><tr><th>特性</th><th>GPU（如 NVIDIA）</th><th>TPU（Google）</th></tr></thead><tbody><tr><td>设计目标</td><td>通用并行计算（图形渲染、科学计算、AI 等）</td><td>专为神经网络推理和训练优化</td></tr><tr><td>架构</td><td>通用性强，灵活</td><td>高度定制化，针对矩阵乘加（MatMul）等操作优化</td></tr><tr><td>精度支持</td><td>支持 FP32、FP16、INT8 等多种精度</td><td>主要优化低精度（如 bfloat16、INT8），适合大规模模型</td></tr><tr><td>能效比</td><td>较高</td><td><strong>更高</strong>（尤其在批量推理和训练时）</td></tr><tr><td>编程生态</td><td>CUDA、PyTorch、TensorFlow 等广泛支持</td><td>主要通过 <strong>TensorFlow / JAX</strong> 使用，对其他框架支持有限</td></tr><tr><td>可用性</td><td>可购买（消费级/数据中心）</td><td><strong>仅通过 Google Cloud 提供</strong>（不能单独购买芯片）</td></tr></tbody></table><hr><h3 id="_3-tpu-的优势" tabindex="-1">3. TPU 的优势 <a class="header-anchor" href="#_3-tpu-的优势" aria-label="Permalink to &quot;3. TPU 的优势&quot;">​</a></h3><ul><li><strong>高吞吐量</strong>：特别适合大规模批量处理（如训练大模型）。</li><li><strong>高能效</strong>：每瓦性能优于 GPU，适合数据中心大规模部署。</li><li><strong>与 TensorFlow/JAX 深度集成</strong>：自动优化计算图，简化分布式训练。</li></ul><hr><h3 id="_4-tpu-的应用场景" tabindex="-1">4. TPU 的应用场景 <a class="header-anchor" href="#_4-tpu-的应用场景" aria-label="Permalink to &quot;4. TPU 的应用场景&quot;">​</a></h3><ul><li>大规模语言模型训练（如 Google 的 PaLM、BERT）</li><li>图像识别、语音识别等深度学习任务</li><li>云端 AI 服务（通过 Google Cloud 的 TPU v2/v3/v4/v5 提供）</li></ul><hr><h3 id="_5-举个例子" tabindex="-1">5. 举个例子 <a class="header-anchor" href="#_5-举个例子" aria-label="Permalink to &quot;5. 举个例子&quot;">​</a></h3><p>如果你在 Google Colab（免费或付费版）中选择 <strong>TPU 运行时</strong>，你的 TensorFlow 或 JAX 代码就会在 Google 的 TPU 硬件上运行，速度可能比普通 CPU 或 GPU 快很多（前提是代码适配 TPU）。</p><h2 id="神经网络的层数" tabindex="-1">神经网络的层数 <a class="header-anchor" href="#神经网络的层数" aria-label="Permalink to &quot;神经网络的层数&quot;">​</a></h2><blockquote><p>“N层神经网络” = N 个 带权重的层（即包含权重 W 和偏置 b 的层）</p></blockquote><ul><li>输入层、隐藏层、输出层</li><li>GoogleNet 网络为22层，ResNet 可以达到50，101，152层</li><li>一般输入层是不计算在层级中</li></ul><h3 id="计算公式-y-x·w-b" tabindex="-1">计算公式 <code>y = x·W + b</code> <a class="header-anchor" href="#计算公式-y-x·w-b" aria-label="Permalink to &quot;计算公式 `y = x·W + b`&quot;">​</a></h3><h3 id="一、w-和-b-是什么单词" tabindex="-1">一、<strong>W 和 b 是什么单词？</strong> <a class="header-anchor" href="#一、w-和-b-是什么单词" aria-label="Permalink to &quot;一、**W 和 b 是什么单词？**&quot;">​</a></h3><ul><li><strong>W</strong> 是 <strong>Weight</strong>（权重）的缩写</li><li><strong>b</strong> 是 <strong>Bias</strong>（偏置）的缩写</li></ul><p>这两个词来源于<strong>线性模型</strong>（如线性回归）和<strong>人工神经元模型</strong>（如感知机）。</p><hr><h3 id="二、为什么计算公式是-y-x·w-b" tabindex="-1">二、<strong>为什么计算公式是：<code>y = x·W + b</code>？</strong> <a class="header-anchor" href="#二、为什么计算公式是-y-x·w-b" aria-label="Permalink to &quot;二、**为什么计算公式是：`y = x·W + b`？**&quot;">​</a></h3><p>这个公式其实是<strong>人工神经元的基本计算方式</strong>，源于对生物神经元的简化模拟。我们一步步解释：</p><hr><h4 id="_1-从生物神经元类比" tabindex="-1">1. <strong>从生物神经元类比</strong> <a class="header-anchor" href="#_1-从生物神经元类比" aria-label="Permalink to &quot;1. **从生物神经元类比**&quot;">​</a></h4><ul><li>生物神经元接收多个输入信号（来自其他神经元）</li><li>每个输入信号有“强度”（类似 <strong>权重 Weight</strong>）</li><li>当总输入超过某个“阈值”，神经元就被激活（发放信号）</li></ul><p>人工神经元模仿这个过程：</p><ul><li>输入：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">x_1, x_2, ..., x_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li><li>权重：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, ..., w_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（表示每个输入的重要性）</li><li>偏置：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>（相当于“激活阈值”的负值）</li></ul><hr><h4 id="_2-数学表达-加权求和-偏置" tabindex="-1">2. <strong>数学表达：加权求和 + 偏置</strong> <a class="header-anchor" href="#_2-数学表达-加权求和-偏置" aria-label="Permalink to &quot;2. **数学表达：加权求和 + 偏置**&quot;">​</a></h4><p>神经元的<strong>总输入（也叫“净输入”或“线性组合”）</strong> 为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y = w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + b </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span></span></p><p>用<strong>向量/矩阵形式</strong>写就是：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">y</mi><mo>=</mo><mi mathvariant="bold">x</mi><mo>⋅</mo><mi mathvariant="bold">W</mi><mo>+</mo><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{y} = \mathbf{x} \cdot \mathbf{W} + \mathbf{b} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathbf">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7694em;vertical-align:-0.0833em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathbf">b</span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord mathbf">x</span></span></span></span> 是输入向量（如 <code>[1.0, 0.5]</code>）</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">W</mi></mrow><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">W</span></span></span></span> 是权重矩阵（每列对应一个神经元的权重）</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathbf">b</span></span></span></span> 是偏置向量（每个神经元一个偏置）</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">y</mi></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span></span></span> 是线性变换后的结果（也叫“pre-activation”）</li></ul><hr><h4 id="_3-为什么需要偏置-b" tabindex="-1">3. <strong>为什么需要偏置 b？</strong> <a class="header-anchor" href="#_3-为什么需要偏置-b" aria-label="Permalink to &quot;3. **为什么需要偏置 b？**&quot;">​</a></h4><p>如果没有偏置，所有决策边界（如分类线）<strong>必须经过原点 (0,0)</strong>，这会严重限制模型的表达能力。</p><p><strong>举个简单例子</strong>（线性分类）：</p><ul><li>假设我们想用一条直线分开两类点</li><li>如果没有偏置，直线只能是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">w_1 x_1 + w_2 x_2 = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>（过原点）</li><li>但加上偏置后，可以是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi>b</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">w_1 x_1 + w_2 x_2 + b = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>，<strong>任意位置的直线都可以表示</strong></li></ul><p>👉 <strong>偏置让模型更灵活，能拟合更复杂的数据分布。</strong></p><hr><h4 id="_4-为什么用矩阵乘法-x-w" tabindex="-1">4. <strong>为什么用矩阵乘法 <code>x @ W</code>？</strong> <a class="header-anchor" href="#_4-为什么用矩阵乘法-x-w" aria-label="Permalink to &quot;4. **为什么用矩阵乘法 `x @ W`？**&quot;">​</a></h4><ul><li>当有多个神经元时（比如隐藏层有3个神经元），每个神经元都有自己的权重向量</li><li>把这些权重向量并排组成矩阵 <strong>W</strong>，就可以<strong>一次性计算所有神经元的加权和</strong></li><li>这就是<strong>向量化计算</strong>，高效且简洁</li></ul><p>例如你的代码中：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]          </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># (1×2)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">W1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># (2×3)</span></span></code></pre></div><p><code>x @ W1</code> 的结果是：</p><ul><li>第1个神经元：1.0×0.1 + 0.5×0.2 = 0.2</li><li>第2个神经元：1.0×0.3 + 0.5×0.4 = 0.5</li><li>第3个神经元：1.0×0.5 + 0.5×0.6 = 0.8<br> → 得到 <code>[0.2, 0.5, 0.8]</code>，再加上 <code>b1 = [0.1, 0.2, 0.3]</code> → <code>[0.3, 0.7, 1.1]</code></li></ul><hr><h3 id="三、总结-公式的意义" tabindex="-1">三、总结：公式的意义 <a class="header-anchor" href="#三、总结-公式的意义" aria-label="Permalink to &quot;三、总结：公式的意义&quot;">​</a></h3><table tabindex="0"><thead><tr><th>符号</th><th>含义</th><th>作用</th></tr></thead><tbody><tr><td><strong>W (Weight)</strong></td><td>权重</td><td>控制每个输入对输出的<strong>影响程度</strong></td></tr><tr><td><strong>b (Bias)</strong></td><td>偏置</td><td>控制神经元的<strong>激活难易程度</strong>（相当于阈值）</td></tr><tr><td><strong>y = x·W + b</strong></td><td>线性变换</td><td>将输入映射到一个新的空间，为非线性激活做准备</td></tr><tr><td><strong>z = activation(a)</strong></td><td>非线性激活</td><td>引入非线性，使网络能拟合复杂函数</td></tr></tbody></table><blockquote><p>💡 <strong>没有非线性激活函数，多层神经网络就等价于单层线性模型</strong>（因为线性组合的线性组合还是线性）。</p></blockquote><hr><h3 id="_3层神经网络" tabindex="-1">3层神经网络 <a class="header-anchor" href="#_3层神经网络" aria-label="Permalink to &quot;3层神经网络&quot;">​</a></h3><img src="/publish/assets/3layer.Bg8ob6yW.jpg" alt="3层神经网络"><h2 id="激活函数" tabindex="-1">激活函数 <a class="header-anchor" href="#激活函数" aria-label="Permalink to &quot;激活函数&quot;">​</a></h2><img src="/publish/assets/activation-function.CxStGLFo.png" alt="激活函数"><p>激活函数（Activation Function） 是一个关键组件，它的主要作用是为<strong>模型引入非线性因素</strong>。如果没有激活函数，无论神经网络有多少层，其整体仍然只是一个线性变换，无法拟合复杂的非线性关系。</p><h3 id="激活函数的作用" tabindex="-1">激活函数的作用 <a class="header-anchor" href="#激活函数的作用" aria-label="Permalink to &quot;激活函数的作用&quot;">​</a></h3><ul><li>决定一个神经元是否应该被“激活”（即是否将信号传递给下一层）</li><li>对输入信号进行非线性变换，使网络能够学习和表示复杂的函数关系</li><li>模拟生物神经元的行为：当输入信号足够强时，神经元才会“放电”输出</li></ul><h3 id="激活函数的混用" tabindex="-1">激活函数的混用 <a class="header-anchor" href="#激活函数的混用" aria-label="Permalink to &quot;激活函数的混用&quot;">​</a></h3><ul><li>同一个网络可以（也常常）使用多种激活函数 -- 在不同层中选择不同的激活函数</li><li>不同任务应选择不同的激活函数，尤其是输出层</li><li>隐藏层的选择相对灵活，但 ReLU 及其变体是当前主流</li><li>同一层一般使用同一种激活函数。同一层混合多种激活函数，技术上允许，但需谨慎使用</li></ul><h3 id="激活函数的意义" tabindex="-1">激活函数的意义 <a class="header-anchor" href="#激活函数的意义" aria-label="Permalink to &quot;激活函数的意义&quot;">​</a></h3><p>如果不用激活函数，就相当于激励函数f(x) = x，此时每一层节点的输入都是上层输出的线性函数，那么无论神经网络有多少层，输出都是输入的线性组合 =&gt; 与没有隐藏层效果相当</p><p>类比：</p><blockquote><p>你用无数个直尺（线性）拼接，永远画不出曲线；但如果你允许在连接处“弯一下”（非线性），就能逼近任意形状。</p></blockquote><h3 id="_3种常见的激活函数" tabindex="-1">3种常见的激活函数 <a class="header-anchor" href="#_3种常见的激活函数" aria-label="Permalink to &quot;3种常见的激活函数&quot;">​</a></h3><img src="/publish/assets/3-activation-functions.kWRJfVa2.png" alt="激活函数"><h2 id="神经网络的训练" tabindex="-1">神经网络的训练 <a class="header-anchor" href="#神经网络的训练" aria-label="Permalink to &quot;神经网络的训练&quot;">​</a></h2><ul><li>循环若干次，每次根据训练数据，计算误差，再通过反向传播算法，更新权重和偏置</li><li>前向传播是为了得出训练数据的预测结果</li><li>根据预测结果和真实标签，计算损失函数值，找到每一层的误差（即梯度）</li><li>反向传播是为了根据误差，更新所有参数（W和b），使损失函数值最小化</li></ul><!--]--></div><!----></div></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/publish/ai/tensorflow" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Previous page</span><span class="title" data-v-e257564d>TensorFlow 基础</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/publish/ai/time-series-analysis" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>时间序列分析</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>基于 MIT 协议发布</p><p class="copyright" data-v-e315a0ad>Copyright © 2024-present</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about.md\":\"BlILEU08\",\"ai_ai-algorithms-in-different-fields.md\":\"CigS2gut\",\"ai_ai-basic-01.md\":\"4ZZk-kky\",\"ai_ai-images-01.md\":\"B0YhJF74\",\"ai_analytical-ai-01.md\":\"D-0E9gQC\",\"ai_coze-01.md\":\"Bir6jqWS\",\"ai_embeddings.md\":\"C4uepbqZ\",\"ai_function-calling-vs-mcp.md\":\"BKsLo8q2\",\"ai_function-calling.md\":\"BsaJhe5U\",\"ai_machine-learning.md\":\"BitPl6Gp\",\"ai_neural-network-01.md\":\"DoDOjPPM\",\"ai_neural-network-02.md\":\"Bo_WUlWb\",\"ai_neural-network-basic.md\":\"BbrnK0yi\",\"ai_rag01.md\":\"BKtpY6eW\",\"ai_slm.md\":\"C5s27sB8\",\"ai_tensorflow.md\":\"CvSnYCuz\",\"ai_time-series-analysis.md\":\"D_EXmSZu\",\"ai_transformer-01.md\":\"ClveA2oS\",\"ai_transformer-02.md\":\"B6LKj5n2\",\"ai_used-car.md\":\"Da02Oi1-\",\"ai_vector-database.md\":\"DSk1xDos\",\"foundation_code.md\":\"DK9KJsHw\",\"foundation_coding-01.md\":\"CqfK0Peu\",\"foundation_data-cleaning.md\":\"DZs6t5zl\",\"foundation_data-science.md\":\"CNDOCre0\",\"foundation_jupyter.md\":\"CNeS4pzq\",\"foundation_linear-algebra-01.md\":\"Bk1PnNes\",\"foundation_linear-algebra-02.md\":\"ufOjZfMF\",\"foundation_probability-theory.md\":\"tbi1Lp98\",\"foundation_python.md\":\"ocvAbidX\",\"foundation_statistics.md\":\"D6aU0Ehq\",\"foundation_wucai-code.md\":\"1Kzio0jN\",\"index.md\":\"Bvro5rc7\",\"other_ai-movie.md\":\"D3LWuPgD\",\"other_deep-search.md\":\"DidQsyzS\",\"other_getting-started.md\":\"D5-zkTrT\",\"other_github-pages.md\":\"D_QCxqUA\",\"other_latex-test.md\":\"dt1ip36x\",\"other_markdown-guide.md\":\"-65R0uff\",\"other_ssh.md\":\"CIN-ryJd\",\"think_ai-benefits-4-pm.md\":\"BaAVegvB\",\"think_junior.md\":\"BvMFzvwF\",\"think_pm.md\":\"C_ktVvln\",\"web_ai-design.md\":\"C10gSzsH\",\"web_cursor-mcp-to-figma.md\":\"D08eoi7Z\",\"web_from-figma-to-mini.md\":\"BkLVvALI\",\"web_hybrid-rendering.md\":\"CCeFoB_z\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"AI时代的技术分享\",\"description\":\"分享技术心得\",\"base\":\"/publish/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"AI时代开发之旅\",\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"文章\",\"link\":\"/list\"},{\"text\":\"关于\",\"link\":\"/about\"}],\"sidebar\":{\"/ai/\":[{\"text\":\"学习笔记\",\"collapsed\":false,\"items\":[{\"text\":\"TensorFlow 基础\",\"link\":\"/ai/tensorflow\"},{\"text\":\"神经网络基础\",\"link\":\"/ai/neural-network-basic\"},{\"text\":\"时间序列分析\",\"link\":\"/ai/time-series-analysis\"},{\"text\":\"二手车预测价格大赛\",\"link\":\"/ai/used-car\"},{\"text\":\"不同领域的 AI 算法\",\"link\":\"/ai/ai-algorithms-in-different-fields\"},{\"text\":\"分析式AI 01\",\"link\":\"/ai/analytical-ai-01\"},{\"text\":\"RAG 01\",\"link\":\"/ai/rag01\"},{\"text\":\"向量数据库\",\"link\":\"/ai/vector-database\"},{\"text\":\"Embeddings\",\"link\":\"/ai/embeddings\"},{\"text\":\"Coze 使用 01\",\"link\":\"/ai/coze-01\"},{\"text\":\"小语言模型的春天到了吗\",\"link\":\"/ai/slm\"},{\"text\":\"AI 生图使用\",\"link\":\"/ai/ai-images-01\"},{\"text\":\"Function Calling vs MCP\",\"link\":\"/ai/function-calling-vs-mcp\"},{\"text\":\"Function Calling 的原始形态\",\"link\":\"/ai/function-calling\"},{\"text\":\"AI 基础 01\",\"link\":\"/ai/ai-basic-01\"},{\"text\":\"Transformer 揭秘02\",\"link\":\"/ai/transformer-02\"},{\"text\":\"Transformer 揭秘01\",\"link\":\"/ai/transformer-01\"},{\"text\":\"神经网络 揭秘02\",\"link\":\"/ai/neural-network-02\"},{\"text\":\"神经网络 揭秘01\",\"link\":\"/ai/neural-network-01\"},{\"text\":\"机器学习，深度学习，强化学习\",\"link\":\"/ai/machine-learning\"}]}],\"/foundation/\":[{\"text\":\"foundation\",\"collapsed\":false,\"items\":[{\"text\":\"wucai-code 使用\",\"link\":\"/foundation/wucai-code\"},{\"text\":\"浅谈数据清洗\",\"link\":\"/foundation/data-cleaning\"},{\"text\":\"数据科学与AI应用开发的关系\",\"link\":\"/foundation/data-science\"},{\"text\":\"AI 辅助编程的注意事项\",\"link\":\"/foundation/coding-01\"},{\"text\":\"AI 辅助编程初体验\",\"link\":\"/foundation/code\"},{\"text\":\"Jupyter 使用\",\"link\":\"/foundation/jupyter\"},{\"text\":\"Python 使用基础\",\"link\":\"/foundation/python\"},{\"text\":\"统计学知识\",\"link\":\"/foundation/statistics\"},{\"text\":\"概率论 01\",\"link\":\"/foundation/probability-theory\"},{\"text\":\"线性代数基础 02\",\"link\":\"/foundation/linear-algebra-02\"},{\"text\":\"线性代数基础 01\",\"link\":\"/foundation/linear-algebra-01\"}]}],\"/other/\":[{\"text\":\"other\",\"collapsed\":false,\"items\":[{\"text\":\"AI 的深度检索\",\"link\":\"/other/deep-search\"},{\"text\":\"AI 制作长视频实践\",\"link\":\"/other/ai-movie\"},{\"text\":\"使用 GitHub Pages 部署静态网站\",\"link\":\"/other/github-pages\"},{\"text\":\"LaTeX 测试页面\",\"link\":\"/other/latex-test\"},{\"text\":\"Markdown 语法完全指南\",\"link\":\"/other/markdown-guide\"},{\"text\":\"开始使用 VitePress 搭建技术博客\",\"link\":\"/other/getting-started\"},{\"text\":\"ssh 原理图\",\"link\":\"/other/ssh\"}]}],\"/think/\":[{\"text\":\"观察思考\",\"collapsed\":false,\"items\":[{\"text\":\"AI时代初级岗位是否存在\",\"link\":\"/think/junior\"},{\"text\":\"AI 给产品经理带来的帮助\",\"link\":\"/think/ai-benefits-4-pm\"},{\"text\":\"AI草莽时代的产品经理肖像分析\",\"link\":\"/think/pm\"}]}],\"/web/\":[{\"text\":\"前端开发\",\"collapsed\":false,\"items\":[{\"text\":\"Figma MCP 与 Cursor 配合使用\",\"link\":\"/web/cursor-mcp-to-figma\"},{\"text\":\"从 Figma 还原小程序代码\",\"link\":\"/web/from-figma-to-mini\"},{\"text\":\"AI时代设计开发工作流\",\"link\":\"/web/ai-design\"},{\"text\":\"web 网站的混合渲染\",\"link\":\"/web/hybrid-rendering\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/johnyu2023\"},{\"icon\":\"rss\",\"link\":\"/publish/rss.xml\"}],\"footer\":{\"message\":\"基于 MIT 协议发布\",\"copyright\":\"Copyright © 2024-present\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>