import{_ as t,a as e}from"./chunks/diff-between-gen-and-analytical.Dno_Pmk9.js";import{_ as i,C as r,c as m,o as u,G as p,w as c,j as l,a as s}from"./chunks/framework.CdkaGE7W.js";const h="/publish/assets/ai-tool-packages.BbIdoZ4Y.png",o="/publish/assets/svm.Dqxbp6hq.png",g="/publish/assets/5.ByHUM206.png",w=JSON.parse('{"title":"分析式AI 01","description":"AI 用于分析数据、识别模式、支持决策等分析性任务","frontmatter":{"title":"分析式AI 01","description":"AI 用于分析数据、识别模式、支持决策等分析性任务","date":"2025-09-17T00:00:00.000Z","tags":["Analytical AI"]},"headers":[],"relativePath":"ai/analytical-ai-01.md","filePath":"ai/analytical-ai-01.md"}'),d={name:"ai/analytical-ai-01.md"};function y(b,a,v,x,k,f){const n=r("BlogPost");return u(),m("div",null,[p(n,null,{default:c(()=>[...a[0]||(a[0]=[l("img",{src:t,alt:"analytical-ai"},null,-1),l("h2",{id:"分析式ai与生成式ai",tabindex:"-1"},[l("code",null,"分析式AI"),s("与"),l("code",null,"生成式AI"),s(),l("a",{class:"header-anchor",href:"#分析式ai与生成式ai","aria-label":'Permalink to "`分析式AI`与`生成式AI`"'},"​")],-1),l("ul",null,[l("li",null,"分析式AI - (Analytical AI)"),l("li",null,"生成式AI - (Generative AI)")],-1),l("h3",{id:"二者的对比",tabindex:"-1"},[s("二者的对比 "),l("a",{class:"header-anchor",href:"#二者的对比","aria-label":'Permalink to "二者的对比"'},"​")],-1),l("img",{src:e,alt:"diff"},null,-1),l("ul",null,[l("li",null,"如果公司的数据资产主要是文字、图像或影片之类的非结构化内容，就应优先采用生成式AI。"),l("li",null,"如果公司的数据大部分都是结构化、数字化，就应偏重分析式AI。"),l("li",null,"生成式AI可以通过内容制作带来回报；"),l("li",null,"分析式AI通常运用预测模型来预测需求、做出数据驱动的决策，从而带来更优异的经济回报。")],-1),l("h3",{id:"二者结合使用",tabindex:"-1"},[s("二者结合使用 "),l("a",{class:"header-anchor",href:"#二者结合使用","aria-label":'Permalink to "二者结合使用"'},"​")],-1),l("ul",null,[l("li",null,"企业内部，做的很多决策，不能用生成式 AI 来分析数据，很不稳定，不可信任，只能用机器学习，统计分析。"),l("li",null,"用生成式 AI 来生成机器学习的算法，用生成的算法来进行数据分析。"),l("li",null,"分析式 AI 来分析数据，更稳定、可靠，并且可溯源、可解释。")],-1),l("h2",{id:"机器学习的模型",tabindex:"-1"},[s("机器学习的模型 "),l("a",{class:"header-anchor",href:"#机器学习的模型","aria-label":'Permalink to "机器学习的模型"'},"​")],-1),l("h3",{id:"数据集",tabindex:"-1"},[s("数据集 "),l("a",{class:"header-anchor",href:"#数据集","aria-label":'Permalink to "数据集"'},"​")],-1),l("ul",null,[l("li",null,"国外的 kaggle , 有很多的数据集，都可以用来训练模型。"),l("li",null,"国内的 阿里云的天池 , 有很多的数据集，都可以用来训练模型。")],-1),l("h3",{id:"机器学习的十大经典模型-kaggle-上投票选出来的模型",tabindex:"-1"},[s("机器学习的十大经典模型 - kaggle 上投票选出来的模型 "),l("a",{class:"header-anchor",href:"#机器学习的十大经典模型-kaggle-上投票选出来的模型","aria-label":'Permalink to "机器学习的十大经典模型 - kaggle 上投票选出来的模型"'},"​")],-1),l("ul",null,[l("li",null,"分类/回归算法：C4.5，朴素贝叶斯（Naive Bayes），SVM，KNN，Adaboost，CART -- 分类和回归的区别就是最后加一个函数的事，所以本质上是一类"),l("li",null,"聚类算法：K-Means，EM"),l("li",null,"关联分析：Apriori"),l("li",null,"连接分析：PageRank")],-1),l("h3",{id:"经典模型的类型解释",tabindex:"-1"},[s("经典模型的类型解释 "),l("a",{class:"header-anchor",href:"#经典模型的类型解释","aria-label":'Permalink to "经典模型的类型解释"'},"​")],-1),l("ul",null,[l("li",null,[s("分类算法：预测一个样本属于某一类别的概率。 -- "),l("strong",null,"按标准答案预测类别"),s(" -- 御姐还是萝莉")]),l("li",null,[s("聚类算法：将样本分组，使得组内的样本相似度高，组间的样本相似度低。 -- "),l("strong",null,"按相似性自动分组"),s(" -- 自动分组找规律")]),l("li",null,"关联分析：发现数据中隐藏的关联规则。 -- 找闺蜜 -- 例：酒和尿布"),l("li",null,"链接分析：评估大型数据集中不同实体（或节点）之间的关系。-- Link Analysis Algorithm -- 找影响力")],-1),l("h3",{id:"分类算法和聚类算法的对比",tabindex:"-1"},[s("分类算法和聚类算法的对比 "),l("a",{class:"header-anchor",href:"#分类算法和聚类算法的对比","aria-label":'Permalink to "分类算法和聚类算法的对比"'},"​")],-1),l("blockquote",null,[l("p",null,[l("strong",null,"分类是有监督学习，聚类是无监督学习。")])],-1),l("h4",{id:"📌-一、定义区别",tabindex:"-1"},[s("📌 一、定义区别 "),l("a",{class:"header-anchor",href:"#📌-一、定义区别","aria-label":'Permalink to "📌 一、定义区别"'},"​")],-1),l("table",{tabindex:"0"},[l("thead",null,[l("tr",null,[l("th",null,"项目"),l("th",null,"分类算法（Classification）"),l("th",null,"聚类算法（Clustering）")])]),l("tbody",null,[l("tr",null,[l("td",null,"学习类型"),l("td",null,"有监督学习（Supervised Learning）"),l("td",null,"无监督学习（Unsupervised Learning）")]),l("tr",null,[l("td",null,"是否需要标签"),l("td",null,"需要已知标签的训练数据"),l("td",null,"不需要标签，自动发现数据结构")]),l("tr",null,[l("td",null,"目标"),l("td",null,"预测新样本属于哪个预定义类别"),l("td",null,"将相似样本自动分组，发现隐藏模式")]),l("tr",null,[l("td",null,"输出"),l("td",null,"明确的类别标签（如“猫”、“狗”）"),l("td",null,"簇编号或分组（如“组1”、“组2”）")])])],-1),l("h4",{id:"📌-二、简单举例说明",tabindex:"-1"},[s("📌 二、简单举例说明 "),l("a",{class:"header-anchor",href:"#📌-二、简单举例说明","aria-label":'Permalink to "📌 二、简单举例说明"'},"​")],-1),l("h5",{id:"✅-分类算法例子-垃圾邮件识别",tabindex:"-1"},[s("✅ 分类算法例子：垃圾邮件识别 "),l("a",{class:"header-anchor",href:"#✅-分类算法例子-垃圾邮件识别","aria-label":'Permalink to "✅ 分类算法例子：垃圾邮件识别"'},"​")],-1),l("ul",null,[l("li",null,[l("strong",null,"任务"),s("：判断一封邮件是“垃圾邮件”还是“正常邮件”。")]),l("li",null,[l("strong",null,"训练数据"),s("：已有大量邮件被人工标记为“垃圾”或“正常”。")]),l("li",null,[l("strong",null,"算法"),s("：逻辑回归、决策树、SVM等。")]),l("li",null,[l("strong",null,"过程"),s("：模型从带标签的数据中学习特征（如关键词、发件人等），然后对新邮件进行分类。")]),l("li",null,[l("strong",null,"关键"),s("：必须有“正确答案”（标签）来训练模型。")])],-1),l("h5",{id:"✅-聚类算法例子-客户分群",tabindex:"-1"},[s("✅ 聚类算法例子：客户分群 "),l("a",{class:"header-anchor",href:"#✅-聚类算法例子-客户分群","aria-label":'Permalink to "✅ 聚类算法例子：客户分群"'},"​")],-1),l("ul",null,[l("li",null,[l("strong",null,"任务"),s("：将电商平台的客户自动分成不同群体，以便精准营销。")]),l("li",null,[l("strong",null,"训练数据"),s("：只有客户的购买行为、浏览记录等，"),l("strong",null,"没有预先定义的群体标签"),s("。")]),l("li",null,[l("strong",null,"算法"),s("：K-Means、层次聚类、DBSCAN等。")]),l("li",null,[l("strong",null,"过程"),s("：算法根据客户行为的相似性，自动分成若干组（比如“高消费活跃用户”、“低频低价用户”）。")]),l("li",null,[l("strong",null,"关键"),s("：没有标签，模型自己“发现”结构。")])],-1),l("h3",{id:"聚类思想是降维",tabindex:"-1"},[s("聚类思想是降维 "),l("a",{class:"header-anchor",href:"#聚类思想是降维","aria-label":'Permalink to "聚类思想是降维"'},"​")],-1),l("ul",null,[l("li",null,"将零售转变成批发"),l("li",null,"将5万用户转化为5类用户来处理")],-1),l("h2",{id:"机器学习算法工具包",tabindex:"-1"},[s("机器学习算法工具包 "),l("a",{class:"header-anchor",href:"#机器学习算法工具包","aria-label":'Permalink to "机器学习算法工具包"'},"​")],-1),l("blockquote",null,[l("p",null,"我们都是调包侠")],-1),l("img",{src:h,alt:"sklearn"},null,-1),l("h2",{id:"朴素贝叶斯分类器",tabindex:"-1"},[s("朴素贝叶斯分类器 "),l("a",{class:"header-anchor",href:"#朴素贝叶斯分类器","aria-label":'Permalink to "朴素贝叶斯分类器"'},"​")],-1),l("blockquote",null,[l("p",null,"朴素 - 说明是一种精简的模型")],-1),l("p",null,[s("朴素贝叶斯（Naive Bayes）是一种基于贝叶斯定理的分类算法 。其核心思想是选择具有最高后验概率的类别作为预测结果 。算法名称中的“朴素”（Naive）源于一个关键假设："),l("strong",null,"即假设所有特征（或属性）之间是相互独立的，每个特征独立地对分类结果产生影响。"),s(" 这个独立性假设虽然在现实中往往不成立，但它极大简化模型的计算，使得算法简单且易于理解，尽管可能会牺牲一些准确性 。")],-1),l("p",null,[s("朴素贝叶斯分类器是一种"),l("code",null,"监督式机器学习算法"),s("，常用于"),l("code",null,"文本分类"),s("等任务 。它通过给定的训练集，以特征之间相互独立为前提，学习输入（特征）到输出（类别）的联合概率分布 。在实际应用中，例如文本分类，多项式朴素贝叶斯会计算每个类别下各个单词出现的条件概率，并假设单词的出现是独立的 。")],-1),l("p",null,[l("strong",null,"举例说明：")],-1),l("p",null,"一个经典的例子是医院的病人诊断 。假设早上收治了六个病人，记录了他们的症状（如打喷嚏、头痛）和职业（如护士、农夫），以及最终诊断的疾病（如感冒、过敏）。",-1),l("ul",null,[l("li",null,"病人1: 打喷嚏, 护士 -> 感冒"),l("li",null,"病人2: 打喷嚏, 农夫 -> 过敏"),l("li",null,"... (其他病人数据)")],-1),l("p",null,"现在，来了一个新病人，症状是“打喷嚏”，职业是“建筑工人”。朴素贝叶斯算法会利用训练数据计算：",-1),l("ol",null,[l("li",null,"先验概率：比如P(感冒)、P(过敏)。"),l("li",null,"条件概率：比如P(打喷嚏|感冒)、P(打喷嚏|过敏)、P(建筑工人|感冒)、P(建筑工人|过敏)。（这里假设“打喷嚏”和“职业”这两个特征相互独立 ）。"),l("li",null,"应用贝叶斯定理计算后验概率：P(感冒|打喷嚏, 建筑工人) 和 P(过敏|打喷嚏, 建筑工人)。"),l("li",null,"选择后验概率更大的疾病作为预测结果。")],-1),l("p",null,"另一个常见的应用是垃圾邮件过滤 。算法会学习垃圾邮件和正常邮件中各个词语（特征）出现的频率（条件概率），然后根据新邮件中包含的词语，计算其属于垃圾邮件和正常邮件的后验概率，从而进行分类。",-1),l("h3",{id:"朴素贝叶斯分类",tabindex:"-1"},[s("朴素贝叶斯分类 "),l("a",{class:"header-anchor",href:"#朴素贝叶斯分类","aria-label":'Permalink to "朴素贝叶斯分类"'},"​")],-1),l("ul",null,[l("li",null,"常用于文本分类，文本过滤、情感预测、推荐系统等，尤其是对于英文等语言来说，分类效果很好"),l("li",null,"准备阶段，需要确定特征属性，属性值以及label => 训练集"),l("li",null,"训练阶段，输入是特征属性和训练样本，输出是分类器，主要工作是计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率"),l("li",null,"应用阶段，使用分类器对新数据进行分类")],-1),l("h4",{id:"朴素贝叶斯的实际使用",tabindex:"-1"},[s("朴素贝叶斯的实际使用 "),l("a",{class:"header-anchor",href:"#朴素贝叶斯的实际使用","aria-label":'Permalink to "朴素贝叶斯的实际使用"'},"​")],-1),l("ul",null,[l("li",null,"朴素贝叶斯最大的特点是简单、直接，因为每个概率都很容易算"),l("li",null,"它的价值在于预估")],-1),l("h2",{id:"决策树与随机森林",tabindex:"-1"},[s("决策树与随机森林 "),l("a",{class:"header-anchor",href:"#决策树与随机森林","aria-label":'Permalink to "决策树与随机森林"'},"​")],-1),l("h3",{id:"决策树",tabindex:"-1"},[s("决策树 "),l("a",{class:"header-anchor",href:"#决策树","aria-label":'Permalink to "决策树"'},"​")],-1),l("blockquote",null,[l("p",null,"决策树是 AI 自动帮你画了一棵树，其实它会模拟出很多种树，自动帮你找一颗最优的树")],-1),l("ul",null,[l("li",null,"决策树基本上就是把我们以前的经验总结出来"),l("li",null,"常见的决策树算法有C4.5、ID3和CART")],-1),l("h3",{id:"信息、熵以及信息增益",tabindex:"-1"},[s("信息、熵以及信息增益 "),l("a",{class:"header-anchor",href:"#信息、熵以及信息增益","aria-label":'Permalink to "信息、熵以及信息增益"'},"​")],-1),l("blockquote",null,[l("p",null,"“决策树”是怎么做决定的。它背后靠的是三个词：信息、熵、信息增益。")],-1),l("ul",null,[l("li",null,"在决策树构建过程中，算法会计算每个特征的信息增益，选择增益最大的那个特征来划分数据，使得划分后的子集尽可能“纯净”（熵小）。这个过程会递归进行，直到满足停止条件，最终形成一棵决策树。")],-1),l("h4",{id:"什么是-信息-——-消除-不知道",tabindex:"-1"},[s("什么是“信息”？—— 消除“不知道” "),l("a",{class:"header-anchor",href:"#什么是-信息-——-消除-不知道","aria-label":'Permalink to "什么是“信息”？—— 消除“不知道”"'},"​")],-1),l("blockquote",null,[l("p",null,"信息是用来消除随机不确定性的东西（香农）")],-1),l("ul",null,[l("li",null,"“信息”的作用就是减少你对某件事的“不知道”程度。你越不确定一件事，知道它的结果后获得的信息就越多。")],-1),l("p",null,[s("📌 "),l("strong",null,"举例")],-1),l("p",null,"假设你抛一枚硬币：",-1),l("ul",null,[l("li",null,"如果硬币是公平的（50%正面，50%反面），你完全不知道结果 → 不确定性高 → 得知结果后获得“信息量大”。"),l("li",null,"如果硬币做了手脚，99%是正面 → 你几乎能猜到结果 → 不确定性低 → 得知结果后获得“信息量小”。")],-1),l("p",null,"所以，“信息量”和“不确定性”成正比。",-1),l("hr",null,null,-1),l("h4",{id:"越不可能发生的事-信息量越大",tabindex:"-1"},[s("越不可能发生的事，信息量越大 "),l("a",{class:"header-anchor",href:"#越不可能发生的事-信息量越大","aria-label":'Permalink to "越不可能发生的事，信息量越大"'},"​")],-1),l("ul",null,[l("li",null,"对于机器学习中的决策树而言，如果带分类的事物集合可以划分为多个类别当中，则某个类（xᵢ）的信息可以定义为")],-1),l("p",{class:"katex-block"},[l("span",{class:"katex-display"},[l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[l("semantics",null,[l("mrow",null,[l("menclose",{notation:"box"},[l("mstyle",{scriptlevel:"0",displaystyle:"false"},[l("mstyle",{scriptlevel:"0",displaystyle:"false"},[l("mstyle",{scriptlevel:"0",displaystyle:"true"},[l("mrow",null,[l("mi",null,"I"),l("mo",{stretchy:"false"},"("),l("mi",null,"X"),l("mo",null,"="),l("msub",null,[l("mi",null,"x"),l("mi",null,"i")]),l("mo",{stretchy:"false"},")"),l("mo",null,"="),l("mo",null,"−"),l("msub",null,[l("mrow",null,[l("mi",null,"log"),l("mo",null,"⁡")]),l("mn",null,"2")]),l("mi",null,"P"),l("mo",{stretchy:"false"},"("),l("msub",null,[l("mi",null,"x"),l("mi",null,"i")]),l("mo",{stretchy:"false"},")")])])])])])]),l("annotation",{encoding:"application/x-tex"},"\\boxed{I(X = x_i) = -\\log_2 P(x_i)} ")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"1.68em","vertical-align":"-0.59em"}}),l("span",{class:"mord"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"1.09em"}},[l("span",{style:{top:"-3.68em"}},[l("span",{class:"pstrut",style:{height:"3.68em"}}),l("span",{class:"boxpad"},[l("span",{class:"mord"},[l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"I"),l("span",{class:"mopen"},"("),l("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mrel"},"="),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"x"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3117em"}},[l("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mathnormal mtight"},"i")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mclose"},")"),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mrel"},"="),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mord"},"−"),l("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),l("span",{class:"mop"},[l("span",{class:"mop"},[s("lo"),l("span",{style:{"margin-right":"0.01389em"}},"g")]),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.207em"}},[l("span",{style:{top:"-2.4559em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"2")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.2441em"}},[l("span")])])])])]),l("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),l("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),l("span",{class:"mopen"},"("),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"x"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3117em"}},[l("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mathnormal mtight"},"i")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mclose"},")")])])])]),l("span",{style:{top:"-3.09em"}},[l("span",{class:"pstrut",style:{height:"3.68em"}}),l("span",{class:"stretchy fbox",style:{height:"1.68em","border-style":"solid","border-width":"0.04em"}})])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.59em"}},[l("span")])])])])])])])])],-1),l("blockquote",null,[l("p",null,"这个公式告诉我们：一个事件发生时带来的“信息量”，等于它发生概率的负对数。越不可能发生的事，信息量越大 —— 它帮我们量化了“惊讶程度”，是整个信息论和决策树算法的基石。")],-1),l("p",null,[s("📌 "),l("strong",null,"举例")],-1),l("p",null,"设随机变量 X 表示“天气”，可能取值：",-1),l("ul",null,[l("li",null,"x₁ = “晴天”，P(x₁) = 0.6 → I(X = x₁) = -log₂(0.6) ≈ 0.74 bit"),l("li",null,"x₂ = “雨天”，P(x₂) = 0.3 → I(X = x₂) = -log₂(0.3) ≈ 1.74 bit"),l("li",null,"x₃ = “雪天”，P(x₃) = 0.1 → I(X = x₃) = -log₂(0.1) ≈ 3.32 bit")],-1),l("blockquote",null,[l("p",null,"这里 P(x₁), P(x₂), P(x₃) 就是简写，实际就是 P(X=x₁) 等。")],-1),l("p",null,"“雪天”最稀有，所以一旦发生，带来的“信息”最多。",-1),l("hr",null,null,-1),l("h4",{id:"什么是-熵-——-衡量-乱不乱",tabindex:"-1"},[s("什么是“熵”？—— 衡量“乱不乱” "),l("a",{class:"header-anchor",href:"#什么是-熵-——-衡量-乱不乱","aria-label":'Permalink to "什么是“熵”？—— 衡量“乱不乱”"'},"​")],-1),l("blockquote",null,[l("p",null,"熵 = 信息的期望值，用来度量不确定性")],-1),l("ul",null,[l("li",null,"熵（Entropy）是所有可能事件的信息量按概率加权平均，也就是“平均不确定性”。")],-1),l("p",null,[s("公式："),l("br"),l("strong",null,"H(X) = - Σ P(xi) * log(P(xi))")],-1),l("ul",null,[l("li",null,"熵越大 → 整体不确定性越高 → 越“混乱”"),l("li",null,"熵越小 → 越确定 → 越“纯净”")],-1),l("p",null,[s("📌 "),l("strong",null,"举例")],-1),l("p",null,"还是成绩分类：",-1),l("p",null,[s("情况1：P(优秀)=0.1, P(良好)=0.3, P(及格)=0.6"),l("br"),s(" → 熵 = -(0.1×log0.1 + 0.3×log0.3 + 0.6×log0.6) ≈ 1.29")],-1),l("p",null,[s("情况2：P(优秀)=0.33, P(良好)=0.33, P(及格)=0.33"),l("br"),s(" → 熵 = -3×(0.33×log0.33) ≈ 1.58")],-1),l("p",null,"→ 情况2更“平均”，不确定性更高，熵更大。",-1),l("p",null,"在决策树中，我们希望划分后的子集“熵小”——也就是类别更“纯净”，比如全是“优秀”或全是“及格”。",-1),l("hr",null,null,-1),l("h4",{id:"什么是-信息增益-——-哪个问题最能-拨开迷雾",tabindex:"-1"},[s("什么是“信息增益”？—— 哪个问题最能“拨开迷雾” "),l("a",{class:"header-anchor",href:"#什么是-信息增益-——-哪个问题最能-拨开迷雾","aria-label":'Permalink to "什么是“信息增益”？—— 哪个问题最能“拨开迷雾”"'},"​")],-1),l("blockquote",null,[l("p",null,"信息增益 = 选择特征的指标，越大越好")],-1),l("p",null,[s("✅ "),l("strong",null,"意思"),s("："),l("br"),s(" 信息增益衡量的是：用某个特征划分数据后，不确定性（熵）减少了多少。")],-1),l("p",null,[s("公式："),l("br"),l("strong",null,"信息增益 = 划分前的熵 - 划分后的加权平均熵")],-1),l("ul",null,[l("li",null,"增益越大 → 这个特征划分效果越好 → 越适合用来做决策节点")],-1),l("p",null,[s("📌 "),l("strong",null,"举例")],-1),l("p",null,"假设我们要预测学生是否“优秀”，有两个特征可选：“是否熬夜”和“是否复习”。",-1),l("ul",null,[l("li",null,"用“是否复习”划分后，熵从 1.0 降到 0.3 → 信息增益 = 0.7"),l("li",null,"用“是否熬夜”划分后，熵从 1.0 降到 0.8 → 信息增益 = 0.2")],-1),l("p",null,"→ “是否复习”信息增益更大，说明它更能帮助我们判断学生是否优秀，决策树会优先选它作为分裂节点。",-1),l("hr",null,null,-1),l("h3",{id:"随机森林",tabindex:"-1"},[s("随机森林 "),l("a",{class:"header-anchor",href:"#随机森林","aria-label":'Permalink to "随机森林"'},"​")],-1),l("ul",null,[l("li",null,"随机森林是决策树算法的集合，它通过集成多个决策树来提高预测的准确度。"),l("li",null,"多棵树来进行投票"),l("li",null,"用一群人做决策，可能好于一个主角 -- 随机森林的效果可能好于决策树")],-1),l("h2",{id:"svm-工具",tabindex:"-1"},[s("SVM 工具 "),l("a",{class:"header-anchor",href:"#svm-工具","aria-label":'Permalink to "SVM 工具"'},"​")],-1),l("img",{src:o,alt:"SVM 工具"},null,-1),l("ul",null,[l("li",null,"SVM 以前很火，现在用得不多。2012年之后，转向了新工具 -- 神经网络"),l("li",null,"神经网络的特点是，层数可以很深。SVM 有点像浅层的神经网络，它只有一层")],-1),l("hr",null,null,-1),l("h3",{id:"svm-里的-kernel-是超参数",tabindex:"-1"},[s("SVM 里的 kernel 是"),l("code",null,"超参数"),s(),l("a",{class:"header-anchor",href:"#svm-里的-kernel-是超参数","aria-label":'Permalink to "SVM 里的 kernel 是`超参数`"'},"​")],-1),l("ul",null,[l("li",null,[s("在机器学习中，"),l("strong",null,"超参数（Hyperparameter）"),s(" 是指"),l("strong",null,"在模型训练开始之前就需要人为设定的参数"),s("，它们"),l("strong",null,"不是通过训练数据自动学习得到的"),s("，而是用来"),l("strong",null,"控制模型结构或学习过程的行为"),s(" 。")]),l("li",null,[l("strong",null,"超参数是你在训练模型前“告诉模型怎么学”的设置，而模型参数是模型“自己从数据中学到的东西”。")]),l("li",null,[s("在 SVM 中，"),l("code",null,"kernel"),s(" 就是一个关键超参数，它决定了模型使用哪种几何方式去划分数据。")])],-1),l("hr",null,null,-1),l("h4",{id:"举个例子-svm-中的-kernel",tabindex:"-1"},[s("举个例子：SVM 中的 kernel "),l("a",{class:"header-anchor",href:"#举个例子-svm-中的-kernel","aria-label":'Permalink to "举个例子：SVM 中的 kernel"'},"​")],-1),l("p",null,[s("在支持向量机（SVM）中， "),l("strong",null,[l("code",null,"kernel"),s("（核函数）")]),s(" 就是一个典型的超参数。它决定了 SVM 如何将原始数据映射到高维空间以实现分类（或回归）：")],-1),l("ul",null,[l("li",null,[s("可选值如："),l("code",null,"linear"),s("（线性）、"),l("code",null,"poly"),s("（多项式）、"),l("code",null,"rbf"),s("（高斯径向基）、"),l("code",null,"sigmoid"),s(" 等。")]),l("li",null,[s("选择不同的 "),l("code",null,"kernel"),s("，相当于使用"),l("strong",null,"完全不同的模型结构"),s("。")])],-1),l("p",null,[s("除了 "),l("code",null,"kernel"),s("，SVM 还有其他常见超参数，比如：")],-1),l("ul",null,[l("li",null,[l("strong",null,[l("code",null,"C")]),s("：正则化强度（惩罚系数），控制对误分类的容忍度 。")]),l("li",null,[l("strong",null,[l("code",null,"gamma")]),s("（用于 RBF、poly 等核）：决定单个训练样本的影响范围。")])],-1),l("hr",null,null,-1),l("h4",{id:"超参数-vs-模型参数-parameters",tabindex:"-1"},[s("超参数 vs 模型参数（Parameters） "),l("a",{class:"header-anchor",href:"#超参数-vs-模型参数-parameters","aria-label":'Permalink to "超参数 vs 模型参数（Parameters）"'},"​")],-1),l("table",{tabindex:"0"},[l("thead",null,[l("tr",null,[l("th",null,"项目"),l("th",null,"超参数（Hyperparameters）"),l("th",null,"模型参数（Parameters）")])]),l("tbody",null,[l("tr",null,[l("td",null,[l("strong",null,"何时确定")]),l("td",null,"训练前手动设定"),l("td",null,"训练过程中自动学习")]),l("tr",null,[l("td",null,[l("strong",null,"是否从数据中学到")]),l("td",null,"否"),l("td",null,"是")]),l("tr",null,[l("td",null,[l("strong",null,"例子（SVM）")]),l("td",null,[l("code",null,"kernel"),s(", "),l("code",null,"C"),s(", "),l("code",null,"gamma")]),l("td",null,[s("支持向量、权重向量 "),l("strong",null,"w"),s("、偏置 "),l("strong",null,"b")])]),l("tr",null,[l("td",null,[l("strong",null,"作用")]),l("td",null,"控制模型复杂度、学习方式"),l("td",null,"描述模型本身的具体决策边界")])])],-1),l("hr",null,null,-1),l("h4",{id:"如何选择超参数",tabindex:"-1"},[s("如何选择超参数？ "),l("a",{class:"header-anchor",href:"#如何选择超参数","aria-label":'Permalink to "如何选择超参数？"'},"​")],-1),l("p",null,"由于超参数不能通过训练直接优化，通常采用以下方法：",-1),l("ul",null,[l("li",null,[l("strong",null,"网格搜索（Grid Search）")]),l("li",null,[l("strong",null,"随机搜索（Random Search）")]),l("li",null,[l("strong",null,"贝叶斯优化（Bayesian Optimization）")]),l("li",null,[l("strong",null,"交叉验证（Cross-validation）"),s(" 评估不同超参数组合的效果")])],-1),l("hr",null,null,-1),l("h3",{id:"svm-里的-kernel-的设定方法",tabindex:"-1"},[s("SVM 里的 kernel 的设定方法 "),l("a",{class:"header-anchor",href:"#svm-里的-kernel-的设定方法","aria-label":'Permalink to "SVM 里的 kernel 的设定方法"'},"​")],-1),l("ul",null,[l("li",null,[s("系统里预先设定了4种 kernel："),l("code",null,"linear"),s("、"),l("code",null,"poly"),s("、"),l("code",null,"rbf"),s("、"),l("code",null,"sigmoid")]),l("li",null,"也可以自己定义 kernel"),l("li",null,"具体用哪一个，需要自己一个一个去试"),l("li",null,"如果试下来，没有一个是适合的，就意味着我们从低维到高维中没有找到一个合适的映射关系")],-1),l("h2",{id:"逻辑回归、线性回归、回归",tabindex:"-1"},[s("逻辑回归、线性回归、回归 "),l("a",{class:"header-anchor",href:"#逻辑回归、线性回归、回归","aria-label":'Permalink to "逻辑回归、线性回归、回归"'},"​")],-1),l("h3",{id:"一、基本定义",tabindex:"-1"},[s("一、基本定义 "),l("a",{class:"header-anchor",href:"#一、基本定义","aria-label":'Permalink to "一、基本定义"'},"​")],-1),l("ol",null,[l("li",null,[l("p",null,[l("strong",null,"回归（Regression）")]),l("ul",null,[l("li",null,[s("是"),l("strong",null,"一类监督学习任务"),s("的总称，目标是"),l("strong",null,"预测连续数值型输出"),s("（比如房价、温度、销售额等）。")]),l("li",null,"回归问题的输出变量是实数（可以是任意实数值）。"),l("li",null,"是围绕一条线来去做预测的")])]),l("li",null,[l("p",null,[l("strong",null,"线性回归（Linear Regression）")]),l("ul",null,[l("li",null,[s("是"),l("strong",null,"回归方法中最基础、最经典的一种"),s("。")]),l("li",null,[s("假设输入特征与输出之间存在"),l("strong",null,"线性关系"),s("，即模型形式为："),l("p",{class:"katex-block"},[l("span",{class:"katex-display"},[l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[l("semantics",null,[l("mrow",null,[l("mi",null,"y"),l("mo",null,"="),l("msub",null,[l("mi",null,"w"),l("mn",null,"1")]),l("msub",null,[l("mi",null,"x"),l("mn",null,"1")]),l("mo",null,"+"),l("msub",null,[l("mi",null,"w"),l("mn",null,"2")]),l("msub",null,[l("mi",null,"x"),l("mn",null,"2")]),l("mo",null,"+"),l("mo",null,"⋯"),l("mo",null,"+"),l("msub",null,[l("mi",null,"w"),l("mi",null,"n")]),l("msub",null,[l("mi",null,"x"),l("mi",null,"n")]),l("mo",null,"+"),l("mi",null,"b")]),l("annotation",{encoding:"application/x-tex"},"y = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b ")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),l("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mrel"},"="),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.7333em","vertical-align":"-0.15em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"1")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"x"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"1")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"+"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.7333em","vertical-align":"-0.15em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"2")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"x"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"2")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"+"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.6667em","vertical-align":"-0.0833em"}}),l("span",{class:"minner"},"⋯"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"+"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.7333em","vertical-align":"-0.15em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.1514em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mathnormal mtight"},"n")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"x"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.1514em"}},[l("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mathnormal mtight"},"n")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"+"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.6944em"}}),l("span",{class:"mord mathnormal"},"b")])])])])])]),l("li",null,[s("用于解决"),l("strong",null,"连续值预测问题"),s("，例如根据房屋面积预测房价。")])])]),l("li",null,[l("p",null,[l("strong",null,"逻辑回归（Logistic Regression）")]),l("ul",null,[l("li",null,[s("虽然名字里有“回归”，但"),l("strong",null,"实际上是一种分类算法"),s("，主要用于"),l("strong",null,"二分类问题"),s("（也可扩展到多分类）。")]),l("li",null,[s("它通过"),l("strong",null,[s("逻辑函数（Sigmoid函数）"),l("strong",null,"将线性组合的结果映射到 (0, 1) 区间，表示属于某一类的"),s("概率")]),s("："),l("p",{class:"katex-block"},[l("span",{class:"katex-display"},[l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[l("semantics",null,[l("mrow",null,[l("mi",null,"P"),l("mo",{stretchy:"false"},"("),l("mi",null,"y"),l("mo",null,"="),l("mn",null,"1"),l("mi",{mathvariant:"normal"},"∣"),l("mi",null,"x"),l("mo",{stretchy:"false"},")"),l("mo",null,"="),l("mfrac",null,[l("mn",null,"1"),l("mrow",null,[l("mn",null,"1"),l("mo",null,"+"),l("msup",null,[l("mi",null,"e"),l("mrow",null,[l("mo",null,"−"),l("mo",{stretchy:"false"},"("),l("msup",null,[l("mi",null,"w"),l("mi",null,"T")]),l("mi",null,"x"),l("mo",null,"+"),l("mi",null,"b"),l("mo",{stretchy:"false"},")")])])])])]),l("annotation",{encoding:"application/x-tex"},"P(y=1|x) = \\frac{1}{1 + e^{-(w^T x + b)}} ")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),l("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),l("span",{class:"mopen"},"("),l("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mrel"},"="),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),l("span",{class:"mord"},"1∣"),l("span",{class:"mord mathnormal"},"x"),l("span",{class:"mclose"},")"),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mrel"},"="),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"2.1256em","vertical-align":"-0.8042em"}}),l("span",{class:"mord"},[l("span",{class:"mopen nulldelimiter"}),l("span",{class:"mfrac"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"1.3214em"}},[l("span",{style:{top:"-2.2791em"}},[l("span",{class:"pstrut",style:{height:"3em"}}),l("span",{class:"mord"},[l("span",{class:"mord"},"1"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"+"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"e"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.8309em"}},[l("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},[l("span",{class:"mord mtight"},"−"),l("span",{class:"mopen mtight"},"("),l("span",{class:"mord mtight"},[l("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.7741em"}},[l("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[l("span",{class:"pstrut",style:{height:"2.5em"}}),l("span",{class:"sizing reset-size3 size1 mtight"},[l("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])]),l("span",{class:"mord mathnormal mtight"},"x"),l("span",{class:"mbin mtight"},"+"),l("span",{class:"mord mathnormal mtight"},"b"),l("span",{class:"mclose mtight"},")")])])])])])])])])])]),l("span",{style:{top:"-3.23em"}},[l("span",{class:"pstrut",style:{height:"3em"}}),l("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),l("span",{style:{top:"-3.677em"}},[l("span",{class:"pstrut",style:{height:"3em"}}),l("span",{class:"mord"},[l("span",{class:"mord"},"1")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.8042em"}},[l("span")])])])]),l("span",{class:"mclose nulldelimiter"})])])])])])])]),l("li",null,[s("输出的是"),l("strong",null,"类别概率"),s("，不是连续数值。")])])])],-1),l("hr",null,null,-1),l("h3",{id:"二、三者的关系",tabindex:"-1"},[s("二、三者的关系 "),l("a",{class:"header-anchor",href:"#二、三者的关系","aria-label":'Permalink to "二、三者的关系"'},"​")],-1),l("ul",null,[l("li",null,[l("strong",null,"线性回归 ⊂ 回归"),s("：线性回归是回归的一种具体实现。")]),l("li",null,[l("strong",null,"逻辑回归 ≠ 回归（在任务类型上）"),s("：尽管逻辑回归使用了“回归”一词，且内部包含线性组合（类似线性回归），但它的目标是"),l("strong",null,"分类"),s("，不是预测连续值。")]),l("li",null,[l("strong",null,"共同点"),s("：两者都基于"),l("strong",null,"线性模型"),s("（即对输入特征做加权求和），但输出层不同（线性 vs Sigmoid）。")])],-1),l("hr",null,null,-1),l("h3",{id:"三、如何区分",tabindex:"-1"},[s("三、如何区分？ "),l("a",{class:"header-anchor",href:"#三、如何区分","aria-label":'Permalink to "三、如何区分？"'},"​")],-1),l("table",{tabindex:"0"},[l("thead",null,[l("tr",null,[l("th",null,"特征"),l("th",null,"回归（广义）"),l("th",null,"线性回归"),l("th",null,"逻辑回归")])]),l("tbody",null,[l("tr",null,[l("td",null,[l("strong",null,"任务类型")]),l("td",null,"预测连续值"),l("td",null,"预测连续值"),l("td",null,[l("strong",null,"分类"),s("（通常是二分类）")])]),l("tr",null,[l("td",null,[l("strong",null,"输出范围")]),l("td",null,"任意实数"),l("td",null,"任意实数"),l("td",null,"(0, 1) 的概率")]),l("tr",null,[l("td",null,[l("strong",null,"激活函数")]),l("td",null,"无（恒等函数）"),l("td",null,"无"),l("td",null,"Sigmoid")]),l("tr",null,[l("td",null,[l("strong",null,"损失函数")]),l("td",null,"均方误差（MSE）"),l("td",null,"均方误差"),l("td",null,"交叉熵（Log Loss）")]),l("tr",null,[l("td",null,[l("strong",null,"典型应用")]),l("td",null,"预测房价、温度"),l("td",null,"同左"),l("td",null,"判断邮件是否为垃圾邮件、用户是否会点击广告")])])],-1),l("h2",{id:"回归函数可以是直线-也可以是曲线",tabindex:"-1"},[s("回归函数可以是直线，也可以是曲线 "),l("a",{class:"header-anchor",href:"#回归函数可以是直线-也可以是曲线","aria-label":'Permalink to "回归函数可以是直线，也可以是曲线"'},"​")],-1),l("blockquote",null,[l("p",null,"我们常常误以为线性回归的线一定是一条直线，但其实一条弯曲的曲线也有可能是线性回归的线")],-1),l("ul",null,[l("li",null,[s("回归函数"),l("strong",null,"不一定是直线"),s("，它"),l("strong",null,"完全可以是曲线"),s("，这取决于你使用的回归模型类型。")])],-1),l("hr",null,null,-1),l("h3",{id:"_1-回归-直线",tabindex:"-1"},[s("1. "),l("strong",null,"“回归” ≠ “直线”"),s(),l("a",{class:"header-anchor",href:"#_1-回归-直线","aria-label":'Permalink to "1. **“回归” ≠ “直线”**"'},"​")],-1),l("ul",null,[l("li",null,[l("strong",null,"回归（Regression）"),s(" 的本质是："),l("strong",null,"用一个函数去拟合数据点之间的关系"),s("，这个函数可以是直线，也可以是曲线。")]),l("li",null,[s("维基百科指出：“回归分析目的在于找出一条最能够代表所有观测资料的"),l("strong",null,"函数曲线"),s("（回归估计式）”。")])],-1),l("hr",null,null,-1),l("h3",{id:"_2-线性回归-只能拟合直线",tabindex:"-1"},[s("2. "),l("strong",null,"线性回归 ≠ 只能拟合直线？"),s(),l("a",{class:"header-anchor",href:"#_2-线性回归-只能拟合直线","aria-label":'Permalink to "2. **线性回归 ≠ 只能拟合直线？**"'},"​")],-1),l("p",null,"这里有个关键概念容易混淆：",-1),l("h4",{id:"✅-线性回归中的-线性-指的是对参数线性-不是对输入变量线性。",tabindex:"-1"},[s("✅ "),l("strong",null,"线性回归中的“线性”指的是对参数线性，不是对输入变量线性。"),s(),l("a",{class:"header-anchor",href:"#✅-线性回归中的-线性-指的是对参数线性-不是对输入变量线性。","aria-label":'Permalink to "✅ **线性回归中的“线性”指的是对参数线性，不是对输入变量线性。**"'},"​")],-1),l("ul",null,[l("li",null,[s("例如："),l("p",{class:"katex-block"},[l("span",{class:"katex-display"},[l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[l("semantics",null,[l("mrow",null,[l("mi",null,"y"),l("mo",null,"="),l("msub",null,[l("mi",null,"β"),l("mn",null,"0")]),l("mo",null,"+"),l("msub",null,[l("mi",null,"β"),l("mn",null,"1")]),l("mi",null,"x"),l("mo",null,"+"),l("msub",null,[l("mi",null,"β"),l("mn",null,"2")]),l("msup",null,[l("mi",null,"x"),l("mn",null,"2")])]),l("annotation",{encoding:"application/x-tex"},"y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 ")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),l("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mrel"},"="),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0528em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"0")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"+"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0528em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"1")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mord mathnormal"},"x"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"+"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"1.0585em","vertical-align":"-0.1944em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0528em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"2")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"x"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.8641em"}},[l("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"2")])])])])])])])])])])])]),s(" 虽然这个函数画出来是一条"),l("strong",null,"抛物线（曲线）"),s("，但它对参数 "),l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("semantics",null,[l("mrow",null,[l("mo",{stretchy:"false"},"("),l("msub",null,[l("mi",null,"β"),l("mn",null,"0")]),l("mo",{separator:"true"},","),l("msub",null,[l("mi",null,"β"),l("mn",null,"1")]),l("mo",{separator:"true"},","),l("msub",null,[l("mi",null,"β"),l("mn",null,"2")]),l("mo",{stretchy:"false"},")")]),l("annotation",{encoding:"application/x-tex"},"(\\beta_0, \\beta_1, \\beta_2)")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),l("span",{class:"mopen"},"("),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0528em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"0")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mpunct"},","),l("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0528em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"1")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mpunct"},","),l("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.3011em"}},[l("span",{style:{top:"-2.55em","margin-left":"-0.0528em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},"2")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.15em"}},[l("span")])])])])]),l("span",{class:"mclose"},")")])])]),s(" 是线性的，所以"),l("strong",null,"仍属于线性回归"),s(" 。")]),l("li",null,[s("这种模型叫 "),l("strong",null,"多项式回归（Polynomial Regression）"),s("，是线性回归的扩展，能拟合曲线。")])],-1),l("blockquote",null,[l("p",null,"正如资料中所说：“如果曲线是一条二次曲线，就被称为二次回归”。")],-1),l("hr",null,null,-1),l("h3",{id:"_3-非线性回归-真正的曲线模型",tabindex:"-1"},[s("3. "),l("strong",null,"非线性回归：真正的曲线模型"),s(),l("a",{class:"header-anchor",href:"#_3-非线性回归-真正的曲线模型","aria-label":'Permalink to "3. **非线性回归：真正的曲线模型**"'},"​")],-1),l("ul",null,[l("li",null,[s("如果模型对参数也是非线性的，比如："),l("p",{class:"katex-block"},[l("span",{class:"katex-display"},[l("span",{class:"katex"},[l("span",{class:"katex-mathml"},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[l("semantics",null,[l("mrow",null,[l("mi",null,"y"),l("mo",null,"="),l("mi",null,"a"),l("mo",null,"⋅"),l("msup",null,[l("mi",null,"e"),l("mrow",null,[l("mi",null,"b"),l("mi",null,"x")])]),l("mo",{separator:"true"},","),l("mspace",{width:"1em"}),l("mi",null,"y"),l("mo",null,"="),l("mfrac",null,[l("mn",null,"1"),l("mrow",null,[l("mn",null,"1"),l("mo",null,"+"),l("msup",null,[l("mi",null,"e"),l("mrow",null,[l("mo",null,"−"),l("mo",{stretchy:"false"},"("),l("mi",null,"a"),l("mi",null,"x"),l("mo",null,"+"),l("mi",null,"b"),l("mo",{stretchy:"false"},")")])])])])]),l("annotation",{encoding:"application/x-tex"},"y = a \\cdot e^{bx}, \\quad y = \\frac{1}{1 + e^{-(ax + b)}} ")])])]),l("span",{class:"katex-html","aria-hidden":"true"},[l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),l("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mrel"},"="),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"0.4445em"}}),l("span",{class:"mord mathnormal"},"a"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"⋅"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"1.0935em","vertical-align":"-0.1944em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"e"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.8991em"}},[l("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},[l("span",{class:"mord mathnormal mtight"},"b"),l("span",{class:"mord mathnormal mtight"},"x")])])])])])])])]),l("span",{class:"mpunct"},","),l("span",{class:"mspace",style:{"margin-right":"1em"}}),l("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),l("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),l("span",{class:"mrel"},"="),l("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),l("span",{class:"base"},[l("span",{class:"strut",style:{height:"2.1088em","vertical-align":"-0.7873em"}}),l("span",{class:"mord"},[l("span",{class:"mopen nulldelimiter"}),l("span",{class:"mfrac"},[l("span",{class:"vlist-t vlist-t2"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"1.3214em"}},[l("span",{style:{top:"-2.296em"}},[l("span",{class:"pstrut",style:{height:"3em"}}),l("span",{class:"mord"},[l("span",{class:"mord"},"1"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mbin"},"+"),l("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),l("span",{class:"mord"},[l("span",{class:"mord mathnormal"},"e"),l("span",{class:"msupsub"},[l("span",{class:"vlist-t"},[l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.814em"}},[l("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[l("span",{class:"pstrut",style:{height:"2.7em"}}),l("span",{class:"sizing reset-size6 size3 mtight"},[l("span",{class:"mord mtight"},[l("span",{class:"mord mtight"},"−"),l("span",{class:"mopen mtight"},"("),l("span",{class:"mord mathnormal mtight"},"a"),l("span",{class:"mord mathnormal mtight"},"x"),l("span",{class:"mbin mtight"},"+"),l("span",{class:"mord mathnormal mtight"},"b"),l("span",{class:"mclose mtight"},")")])])])])])])])])])]),l("span",{style:{top:"-3.23em"}},[l("span",{class:"pstrut",style:{height:"3em"}}),l("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),l("span",{style:{top:"-3.677em"}},[l("span",{class:"pstrut",style:{height:"3em"}}),l("span",{class:"mord"},[l("span",{class:"mord"},"1")])])]),l("span",{class:"vlist-s"},"​")]),l("span",{class:"vlist-r"},[l("span",{class:"vlist",style:{height:"0.7873em"}},[l("span")])])])]),l("span",{class:"mclose nulldelimiter"})])])])])])]),s(" 这些就是"),l("strong",null,"非线性回归模型"),s("，必须用非线性优化方法拟合。")])],-1),l("hr",null,null,-1),l("h3",{id:"_4-常见回归函数类型举例",tabindex:"-1"},[s("4. "),l("strong",null,"常见回归函数类型举例"),s(),l("a",{class:"header-anchor",href:"#_4-常见回归函数类型举例","aria-label":'Permalink to "4. **常见回归函数类型举例**"'},"​")],-1),l("table",{tabindex:"0"},[l("thead",null,[l("tr",null,[l("th",null,"模型类型"),l("th",null,"回归函数形状"),l("th",null,"是否线性模型")])]),l("tbody",null,[l("tr",null,[l("td",null,"简单线性回归"),l("td",null,"直线（(y = ax + b)）"),l("td",null,"是")]),l("tr",null,[l("td",null,"多项式回归"),l("td",null,"抛物线、三次曲线等"),l("td",null,"是（对参数线性）")]),l("tr",null,[l("td",null,"逻辑回归"),l("td",null,"Sigmoid 曲线"),l("td",null,"是（对参数线性）")]),l("tr",null,[l("td",null,"指数回归"),l("td",null,"指数曲线"),l("td",null,"否")]),l("tr",null,[l("td",null,"神经网络回归"),l("td",null,"任意复杂曲线"),l("td",null,"通常否")])])],-1),l("h2",{id:"机器学习的五大门派",tabindex:"-1"},[s("机器学习的五大门派 "),l("a",{class:"header-anchor",href:"#机器学习的五大门派","aria-label":'Permalink to "机器学习的五大门派"'},"​")],-1),l("img",{src:g,alt:"机器学习的五大门派",style:{width:"80%",height:"auto"}},null,-1),l("p",null,"机器学习包括监督学习，无监督学习，半监督学习，强化学习",-1),l("ul",null,[l("li",null,[s("符号学派，认为事情都是有"),l("strong",null,"因果"),s("的，机器可以自己摸索出规律，典型代表为决策树")]),l("li",null,[s("贝叶斯学派，因果之间不是必然发生，是有一定"),l("strong",null,"概率"),s("的，即P(A|B)，典型代表为朴素贝叶斯")]),l("li",null,[s("类推学派，通过类比可以让我们学习到很多未知的知识，所以我们需要先定义"),l("strong",null,"相似度"),s("，通过相似度进行发现")]),l("li",null,"联结学派，模仿人脑神经元的工作原理，所有模式识别和记忆建立在神经元的不同连接方式上，典型代表为神经网络，深度学习"),l("li",null,"进化学派，上帝通过基因选择来适者生存，典型代表为遗传算法")],-1)])]),_:1})])}const _=i(d,[["render",y]]);export{w as __pageData,_ as default};
