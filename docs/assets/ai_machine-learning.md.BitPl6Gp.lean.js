import{_ as o,C as i,c as A,o as t,G as s,w as r,j as l,b as d,a as e,an as B}from"./chunks/framework.CdkaGE7W.js";const b=JSON.parse('{"title":"机器学习，深度学习，强化学习","description":"机器学习，深度学习，强化学习这三个概念，似乎很接近，却又似乎大相径庭","frontmatter":{"title":"机器学习，深度学习，强化学习","description":"机器学习，深度学习，强化学习这三个概念，似乎很接近，却又似乎大相径庭","date":"2025-02-01T00:00:00.000Z","tags":["Machine Learning","Deep Learning","Reinforcement Learning"]},"headers":[],"relativePath":"ai/machine-learning.md","filePath":"ai/machine-learning.md"}'),E={name:"ai/machine-learning.md"};function p(g,n,D,m,C,f){const u=i("Mermaid"),a=i("BlogPost");return t(),A("div",null,[s(a,null,{default:r(()=>[n[1]||(n[1]=l("ul",null,[l("li",null,[e("所有跟"),l("code",null,"算法、模型"),e("有关的都叫"),l("code",null,"机器学习")]),l("li",null,[e("应用了"),l("code",null,"神经网络"),e("的机器学习，叫"),l("code",null,"深度学习")]),l("li",null,"没有神经网络的，就是传统的机器学习，如 逻辑回归、决策树、朴素贝叶斯"),l("li",null,[e("强化学习中依赖"),l("code",null,"奖励"),e("来衡量行为的好坏，它可以使用神经网络，也可以不使用神经网络")])],-1)),n[2]||(n[2]=l("p",null,[e("在人工智能（AI）领域中，"),l("strong",null,"机器学习（Machine Learning）"),e("、"),l("strong",null,"深度学习（Deep Learning）"),e(" 和 "),l("strong",null,"强化学习（Reinforcement Learning）"),e(" 是三个核心概念，它们之间既有区别又有紧密联系。下面我们逐一解释它们的定义、特点以及相互关系。")],-1)),n[3]||(n[3]=l("h2",{id:"基本概念",tabindex:"-1"},[e("基本概念 "),l("a",{class:"header-anchor",href:"#基本概念","aria-label":'Permalink to "基本概念"'},"​")],-1)),n[4]||(n[4]=l("h3",{id:"_1-机器学习-machine-learning-ml",tabindex:"-1"},[e("1. 机器学习（Machine Learning, ML） "),l("a",{class:"header-anchor",href:"#_1-机器学习-machine-learning-ml","aria-label":'Permalink to "1. 机器学习（Machine Learning, ML）"'},"​")],-1)),n[5]||(n[5]=l("p",null,[l("strong",null,"定义"),e("："),l("br"),e(" 机器学习是人工智能的一个子领域，其核心思想是让计算机系统从数据中“学习”规律，从而在没有被明确编程的情况下完成任务。")],-1)),n[6]||(n[6]=l("p",null,[l("strong",null,"关键点"),e("：")],-1)),n[7]||(n[7]=l("ul",null,[l("li",null,"通过训练数据构建模型。"),l("li",null,"模型可以对新数据做出预测或决策。"),l("li",null,"常见任务包括分类、回归、聚类等。")],-1)),n[8]||(n[8]=l("p",null,[l("strong",null,"主要类型"),e("：")],-1)),n[9]||(n[9]=l("ul",null,[l("li",null,[l("strong",null,"监督学习（Supervised Learning）"),e("：有标签数据，如图像分类。")]),l("li",null,[l("strong",null,"无监督学习（Unsupervised Learning）"),e("：无标签数据，如聚类。")]),l("li",null,[l("strong",null,"半监督学习"),e("：部分有标签，部分无标签。")]),l("li",null,[l("strong",null,"强化学习"),e("：见下文。")])],-1)),n[10]||(n[10]=l("p",null,[e("✅ "),l("strong",null,"机器学习是这三者中最广泛的概念，是深度学习和强化学习的“上层分类”"),e("。")],-1)),n[11]||(n[11]=l("h3",{id:"_2-深度学习-deep-learning-dl",tabindex:"-1"},[e("2. 深度学习（Deep Learning, DL） "),l("a",{class:"header-anchor",href:"#_2-深度学习-deep-learning-dl","aria-label":'Permalink to "2. 深度学习（Deep Learning, DL）"'},"​")],-1)),n[12]||(n[12]=l("p",null,[l("strong",null,"定义"),e("："),l("br"),e(" 深度学习是机器学习的一个子集，主要使用"),l("strong",null,"深层神经网络"),e("（如深度神经网络 DNN、卷积神经网络 CNN、循环神经网络 RNN 等）来自动提取数据的特征并进行学习。")],-1)),n[13]||(n[13]=l("p",null,[l("strong",null,"关键点"),e("：")],-1)),n[14]||(n[14]=l("ul",null,[l("li",null,"基于人工神经网络，尤其是“深度”（多层）结构。"),l("li",null,"能自动从原始数据中学习特征，无需人工设计特征。"),l("li",null,"在图像、语音、自然语言处理等领域表现突出。")],-1)),n[15]||(n[15]=l("p",null,[l("strong",null,"典型应用"),e("：")],-1)),n[16]||(n[16]=l("ul",null,[l("li",null,"图像识别（如人脸识别）"),l("li",null,"语音识别（如 Siri）"),l("li",null,"自然语言处理（如 GPT、BERT）")],-1)),n[17]||(n[17]=l("p",null,[e("✅ "),l("strong",null,"深度学习是机器学习的一种方法，特别适合处理高维、非结构化数据（如图像、文本、音频）"),e("。")],-1)),n[18]||(n[18]=l("h3",{id:"_3-强化学习-reinforcement-learning-rl",tabindex:"-1"},[e("3. 强化学习（Reinforcement Learning, RL） "),l("a",{class:"header-anchor",href:"#_3-强化学习-reinforcement-learning-rl","aria-label":'Permalink to "3. 强化学习（Reinforcement Learning, RL）"'},"​")],-1)),n[19]||(n[19]=l("p",null,[l("strong",null,"定义"),e("："),l("br"),e(" 强化学习是一种通过与环境交互来学习“最优策略”的机器学习方法。智能体（Agent）通过尝试动作、获得奖励或惩罚，逐步学会在特定环境中做出最佳决策。")],-1)),n[20]||(n[20]=l("blockquote",null,[l("p",null,"强化学习（Reinforcement Learning, RL）本质上必须依赖“奖励”信号来衡量行为的好坏（即“对错”），从而指导学习。区别在于："),l("ul",null,[l("li",null,"传统 RL：使用预定义的奖励函数（Reward Function）"),l("li",null,"现代 RL（尤其是大模型场景）：使用学习得到的奖励模型（Reward Model）")])],-1)),n[21]||(n[21]=l("p",null,[l("strong",null,"关键点"),e("：")],-1)),n[22]||(n[22]=l("ul",null,[l("li",null,"核心是“试错”和“延迟奖励”。"),l("li",null,"智能体 → 动作 → 环境反馈（奖励/状态变化）→ 更新策略。"),l("li",null,"目标是最大化长期累积奖励。")],-1)),n[23]||(n[23]=l("p",null,[l("strong",null,"典型应用"),e("：")],-1)),n[24]||(n[24]=l("ul",null,[l("li",null,"游戏 AI（如 AlphaGo）"),l("li",null,"机器人控制"),l("li",null,"自动驾驶决策系统")],-1)),n[25]||(n[25]=l("p",null,[e("✅ "),l("strong",null,"强化学习是机器学习的另一种范式，强调“决策”和“序列行为”"),e("。")],-1)),n[26]||(n[26]=l("h2",{id:"三者的关系-图示逻辑",tabindex:"-1"},[e("三者的关系（图示逻辑） "),l("a",{class:"header-anchor",href:"#三者的关系-图示逻辑","aria-label":'Permalink to "三者的关系（图示逻辑）"'},"​")],-1)),n[27]||(n[27]=l("div",{class:"language-text vp-adaptive-theme"},[l("button",{title:"Copy Code",class:"copy"}),l("span",{class:"lang"},"text"),l("pre",{class:"shiki shiki-themes github-light github-dark vp-code",tabindex:"0"},[l("code",null,[l("span",{class:"line"},[l("span",null,"人工智能 (AI)")]),e(`
`),l("span",{class:"line"},[l("span",null,"    └── 机器学习 (ML)")]),e(`
`),l("span",{class:"line"},[l("span",null,"           ├── 监督学习")]),e(`
`),l("span",{class:"line"},[l("span",null,"           ├── 无监督学习")]),e(`
`),l("span",{class:"line"},[l("span",null,"           ├── 半监督学习")]),e(`
`),l("span",{class:"line"},[l("span",null,"           ├── 深度学习（DL）← 可应用于各类学习范式")]),e(`
`),l("span",{class:"line"},[l("span",null,"           └── 强化学习 (RL)")]),e(`
`),l("span",{class:"line"},[l("span",null,"                   └── 深度强化学习（如 DQN, PPO）← 深度学习 + 强化学习")])])])],-1)),n[28]||(n[28]=l("p",null,"Mermaid 的图如下：",-1)),(t(),d(B,null,{default:r(()=>[s(u,{id:"mermaid-205",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20A%5B%22%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%20(AI)%22%5D%20--%3E%20B%5B%22%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20(Machine%20Learning)%22%5D%0A%20%20%20%20B%20--%3E%20C%5B%22%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%22%5D%0A%20%20%20%20B%20--%3E%20D%5B%22%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%22%5D%0A%20%20%20%20B%20--%3E%20E%5B%22%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%22%5D%0A%20%20%20%20B%20--%3E%20F%5B%22%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%20(Reinforcement%20Learning)%22%5D%0A%20%20%20%20B%20--%3E%20G%5B%22%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20(Deep%20Learning)%22%5D%0A%0A%20%20%20%20G%20--%3E%20H%5B%22%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%22%5D%0A%20%20%20%20G%20--%3E%20I%5B%22%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%22%5D%0A%20%20%20%20G%20--%3E%20J%5B%22%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%22%5D%0A%20%20%20%20G%20--%3E%20K%5B%22Transformer%22%5D%0A%0A%20%20%20%20F%20--%3E%20L%5B%22%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%3Cbr%2F%3E%20(Deep%20Reinforcement%20Learning)%22%5D%0A%20%20%20%20G%20--%3E%20L%0A%0A%20%20%20%20style%20A%20fill%3A%234B9CD3%2Cstroke%3A%23333%2Ccolor%3Awhite%0A%20%20%20%20style%20B%20fill%3A%236FC2A4%2Cstroke%3A%23333%0A%20%20%20%20style%20F%20fill%3A%23FFD54F%2Cstroke%3A%23333%0A%20%20%20%20style%20G%20fill%3A%23FF8A65%2Cstroke%3A%23333%0A%20%20%20%20style%20L%20fill%3A%23E1BEE7%2Cstroke%3A%23333%0A%0A%20%20%20%20classDef%20ai%20fill%3A%234B9CD3%2Cstroke%3A%23333%2Ccolor%3Awhite%3B%0A%20%20%20%20classDef%20ml%20fill%3A%236FC2A4%2Cstroke%3A%23333%3B%0A%20%20%20%20classDef%20dl%20fill%3A%23FF8A65%2Cstroke%3A%23333%3B%0A%20%20%20%20classDef%20rl%20fill%3A%23FFD54F%2Cstroke%3A%23333%3B%0A%20%20%20%20classDef%20dprl%20fill%3A%23E1BEE7%2Cstroke%3A%23333%3B%0A%0A%20%20%20%20class%20A%20ai%0A%20%20%20%20class%20B%2CC%2CD%2CE%2CF%2CG%2CH%2CI%2CJ%2CK%20ml%0A%20%20%20%20class%20G%2CH%2CI%2CJ%2CK%20dl%0A%20%20%20%20class%20F%2CL%20rl%0A%20%20%20%20class%20L%20dprl%0A"})]),fallback:r(()=>[...n[0]||(n[0]=[e(" Loading... ",-1)])]),_:1})),n[29]||(n[29]=l("h2",{id:"联系与区别",tabindex:"-1"},[e("联系与区别 "),l("a",{class:"header-anchor",href:"#联系与区别","aria-label":'Permalink to "联系与区别"'},"​")],-1)),n[30]||(n[30]=l("table",{tabindex:"0"},[l("thead",null,[l("tr",null,[l("th",null,"维度"),l("th",null,"机器学习"),l("th",null,"深度学习"),l("th",null,"强化学习")])]),l("tbody",null,[l("tr",null,[l("td",null,"所属关系"),l("td",null,"最大范畴"),l("td",null,"机器学习的子集"),l("td",null,"机器学习的子集")]),l("tr",null,[l("td",null,"核心思想"),l("td",null,"从数据中学习规律"),l("td",null,"使用深层神经网络自动提取特征"),l("td",null,"通过试错和奖励机制学习最优策略")]),l("tr",null,[l("td",null,"是否需要标签"),l("td",null,"监督学习需要，无监督不需要"),l("td",null,"通常需要大量数据，可有可无标签"),l("td",null,"不需要标签，但需要奖励信号")]),l("tr",null,[l("td",null,"典型模型"),l("td",null,"决策树、SVM、随机森林"),l("td",null,"CNN、RNN、Transformer"),l("td",null,"Q-learning、Policy Gradient、DQN")]),l("tr",null,[l("td",null,"适用任务"),l("td",null,"分类、回归、聚类"),l("td",null,"图像、语音、文本处理"),l("td",null,"决策、控制、游戏、路径规划")]),l("tr",null,[l("td",null,"与环境交互"),l("td",null,"通常不交互（批处理）"),l("td",null,"通常不交互"),l("td",null,"必须与环境持续交互")])])],-1)),n[31]||(n[31]=l("h2",{id:"交叉融合-深度强化学习-deep-reinforcement-learning",tabindex:"-1"},[e("交叉融合：深度强化学习（Deep Reinforcement Learning） "),l("a",{class:"header-anchor",href:"#交叉融合-深度强化学习-deep-reinforcement-learning","aria-label":'Permalink to "交叉融合：深度强化学习（Deep Reinforcement Learning）"'},"​")],-1)),n[32]||(n[32]=l("p",null,[e("当"),l("strong",null,"深度学习"),e("与"),l("strong",null,"强化学习"),e("结合时，就产生了"),l("strong",null,"深度强化学习"),e("（Deep RL），它用深度神经网络来表示强化学习中的策略或价值函数。")],-1)),n[33]||(n[33]=l("p",null,[l("strong",null,"例子"),e("：")],-1)),n[34]||(n[34]=l("ul",null,[l("li",null,[l("strong",null,"AlphaGo"),e("：使用深度神经网络评估棋局 + 强化学习优化走棋策略。")]),l("li",null,[l("strong",null,"自动驾驶"),e("：用深度学习感知环境（视觉识别），用强化学习做驾驶决策。")])],-1))]),_:1})])}const k=o(E,[["render",p]]);export{b as __pageData,k as default};
